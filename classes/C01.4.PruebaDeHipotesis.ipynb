{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MOD3WbBv-Wl"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "LuPoG0Dlv-Wn",
        "outputId": "d08956b8-fc80-43d0-9fdf-ced1dd71f998"
      },
      "outputs": [],
      "source": [
        "# To use only Google Colab\n",
        "! pip install matplotlib --upgrade"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfFZNCX5v-Wo"
      },
      "source": [
        "# Unidad I. Variables, distribuciones y pruebas de hipótesis. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYQVyUs-v-Wp"
      },
      "source": [
        "- Estadística inferencial\n",
        "  - test de hipótesis\n",
        "  - Tipos de errores\n",
        "  - Valor P\n",
        "  - Test T de Student para una muestra.\n",
        "  - Intervalo de confianza\n",
        "  - Nivel de confianza\n",
        "  - Bootstrap\n",
        "- Prueba de bondad de ajuste a una distribución.\n",
        "  - chi cuadrado\n",
        "  - Kolmogorov-Smirnov\n",
        "- Comparación de dos poblaciones\n",
        "  - Tests de forma:\n",
        "    - chi cuadrado\n",
        "    - Kolmogorov-Smirnov\n",
        "  - Tests de igualdad de varianza\n",
        "    - Test F\n",
        "    - Test de Bartlett\n",
        "    - Test de Levenne\n",
        "  - Test de igualdad de medias:\n",
        "    - T test para dos muestras.\n",
        "    - Test de Student para variables apareadas.\n",
        "  - Alternativas no paramétricas.\n",
        "    - test de Mann Whitney\n",
        "    - test de Wicolxon.\n",
        "    - test de la Mediana.\n",
        "  - Test para variables cualitativas\n",
        "    - test de fisher.\n",
        "    - test de McNemar.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qvwfsDxv-Wq"
      },
      "source": [
        "## Estadística inferencial\n",
        "\n",
        "La **estadística inferencial** permite **extraer conclusiones o generalizaciones** sobre una **población** a partir del análisis de una **muestra**.\n",
        "\n",
        "Su objetivo principal es estimar parámetros desconocidos y evaluar hipótesis sobre la población basándose en evidencia muestral.\n",
        "\n",
        "### Objetivo\n",
        "\n",
        "* **Inferir** características de una población (media, proporción, varianza, etc.) sin observarla completamente.\n",
        "* **Cuantificar la incertidumbre** asociada a esas inferencias.\n",
        "* **Tomar decisiones** o validar hipótesis mediante métodos probabilísticos.\n",
        "\n",
        "### Tipos de inferencia\n",
        "\n",
        "| Tipo de inferencia            | Descripción                                                                                           | Ejemplo                                                    |\n",
        "| ----------------------------- | ----------------------------------------------------------------------------------------------------- | ---------------------------------------------------------- |\n",
        "| **Estimación puntual**        | Asigna un único valor muestral como mejor estimador del parámetro poblacional.                        | La media muestral como estimador de la media poblacional.  |\n",
        "| **Estimación por intervalos** | Proporciona un **rango de valores plausibles** para el parámetro, con un nivel de confianza asociado. | Intervalo de confianza del 95 % para la media.             |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOHSjajCv-Wq"
      },
      "source": [
        "\n",
        "### Pruebas de hipótesis\n",
        "\n",
        "La **prueba de hipótesis** es un procedimiento estadístico que permite **evaluar una suposición sobre una población** a partir de los datos obtenidos en una muestra.\n",
        "\n",
        "El objetivo no es “probar que algo es cierto”, sino **evaluar si la evidencia observada contradice suficientemente una afirmación inicial**.\n",
        "\n",
        "### Etapas del proceso\n",
        "\n",
        "1. **Formulación de las hipótesis**\n",
        "\n",
        "   * **Hipótesis nula** $ H_0 $:\n",
        "     Representa la situación de “no efecto” o “no diferencia”.\n",
        "\n",
        "     > Ejemplo: “No hay diferencia en el nivel de expresión génica entre tratamientos.”\n",
        "   * **Hipótesis alternativa** $ H_1 $:\n",
        "     Representa el efecto o diferencia que queremos detectar.\n",
        "\n",
        "     > Ejemplo: “El tratamiento A produce una expresión génica distinta al control.”\n",
        "\n",
        "2. **Obtención de una muestra y cálculo del estadístico de prueba**\n",
        "\n",
        "   * Se calcula una medida (estadístico) a partir de los datos muestrales.\n",
        "   * Se compara con lo que se esperaría bajo $ H_0 $.\n",
        "\n",
        "3. **Evaluación de la evidencia (valor p)**\n",
        "\n",
        "   * El **valor p** es la probabilidad de obtener un resultado igual o más extremo que el observado, **si $ H_0 $ fuera verdadera**.\n",
        "   * Si $ p < \\alpha $ (nivel de significancia, típicamente 0.05):\n",
        "     → **Se rechaza $ H_0 $** en favor de $ H_1 $.\n",
        "   * Si $ p \\geq \\alpha $:\n",
        "     → **No se rechaza $ H_0 $** (la evidencia no es suficiente).\n",
        "\n",
        "4. **Interpretación y conclusiones**\n",
        "\n",
        "   * Rechazar $ H_0 $ **no implica probar $ H_1 $**; solo indica que los datos son **inconsistentes con $ H_0 $**.\n",
        "   * No rechazar $ H_0 $ **no significa** que sea verdadera, sino que **no hay evidencia suficiente** para descartarla.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3iOPRUSv-Wr"
      },
      "source": [
        "### Tipos de errores en pruebas de hipótesis\n",
        "\n",
        "En una prueba de hipótesis siempre existe la posibilidad de **tomar una decisión incorrecta**, debido a la variabilidad muestral.\n",
        "Estos errores se clasifican en **dos tipos fundamentales**:\n",
        "\n",
        "#### Tabla de decisiones posibles\n",
        "\n",
        "| **Decisión tomada**     | **$ H_0 $ es verdadera**            | **$ H_1 $ es verdadera**             |\n",
        "| ----------------------- | ----------------------------------- | ------------------------------------ |\n",
        "| **Rechazar $ H_0 $**    | **Error Tipo I** *(Falso Positivo)* | Decisión correcta                    |\n",
        "| **No rechazar $ H_0 $** | Decisión correcta                   | **Error Tipo II** *(Falso Negativo)* |\n",
        "\n",
        "\n",
        "### Error de tipo I $α$ — Falso positivo\n",
        "\n",
        "* Ocurre cuando se **rechaza $ H_0 $** siendo en realidad cierta.\n",
        "* Su probabilidad se denota por **α**, y representa el **nivel de significación estadística** del test.\n",
        "* Es el umbral de tolerancia que definimos para aceptar el riesgo de equivocarnos al detectar un efecto inexistente.\n",
        "\n",
        "$ P(\\text{rechazar } H_0 ,|, H_0 \\text{ es cierta}) = \\alpha $\n",
        "\n",
        "Ejemplo: concluir que un tratamiento tiene efecto cuando en realidad no lo tiene.\n",
        "\n",
        "### Error de tipo II $β$ — Falso negativo\n",
        "\n",
        "* Ocurre cuando se **no se rechaza $ H_0 $** siendo falsa.\n",
        "* Su probabilidad se denota por **β**, y mide la posibilidad de **no detectar un efecto real**.\n",
        "\n",
        "$ P(\\text{no rechazar } H_0 ,|, H_1 \\text{ es cierta}) = \\beta $\n",
        "\n",
        "El **poder estadístico** del test es $ 1 - \\beta $:\n",
        "\n",
        "Es la probabilidad de **detectar correctamente** un efecto cuando realmente existe.\n",
        "\n",
        "### Relación entre α y β\n",
        "\n",
        "* Reducir **α** (ser más estricto) **aumenta** típicamente **β** (más difícil detectar efectos reales).\n",
        "* Un buen diseño experimental busca **equilibrar ambos**, maximizando el **poder** del test sin inflar los falsos positivos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAZzfCjSv-Ws"
      },
      "source": [
        "### Valor p\n",
        "\n",
        "El **valor p** (*p-value*) es una medida fundamental en la inferencia estadística, que cuantifica la **evidencia contra la hipótesis nula**.\n",
        "\n",
        "* Es la **probabilidad de obtener un resultado igual o más extremo que el observado**, **suponiendo que la hipótesis nula ($H_0$) es verdadera**.\n",
        "* En otras palabras, mide **cuán sorprendentes son los datos** si en realidad $H_0$ fuera cierta.\n",
        "\n",
        "$ p = P(\\text{resultado igual o más extremo} \\mid H_0) $\n",
        "\n",
        "### Interpretación\n",
        "\n",
        "* **Valor p bajo** → los datos son **inconsistentes con $H_0$**, se considera **evidencia a favor de $H_1$**.\n",
        "* **Valor p alto** → los datos **no contradicen $H_0$**, no hay evidencia suficiente para rechazarla.\n",
        "\n",
        "### Decisión estadística\n",
        "\n",
        "* Se compara el valor p con el **nivel de significación** $\\alpha$:\n",
        "\n",
        "  * Si $p < \\alpha$ → **rechazo $H_0$** (evidencia estadísticamente significativa).\n",
        "  * Si $p \\geq \\alpha$ → **no rechazo $H_0$** (no hay evidencia suficiente).\n",
        "\n",
        "### Puntos importantes\n",
        "\n",
        "* El **valor p no es la probabilidad de que $H_0$ sea cierta**.\n",
        "* Un valor p **no mide el tamaño del efecto**, solo **la compatibilidad de los datos con $H_0$**.\n",
        "* El umbral $\\alpha$ (por ejemplo, 0.05) debe elegirse **antes del análisis**, según el nivel de error tolerable.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from math import erf\n",
        "\n",
        "# Parámetros\n",
        "z_obs = 1.8      # estadístico observado (ejemplo)\n",
        "two_tailed = True\n",
        "\n",
        "# Funciones auxiliares\n",
        "def phi(x):\n",
        "    return (1.0/np.sqrt(2*np.pi)) * np.exp(-0.5*x*x)\n",
        "\n",
        "def Phi(x):\n",
        "    return 0.5*(1.0 + erf(x/np.sqrt(2.0)))\n",
        "\n",
        "# Cálculo del p-value\n",
        "if two_tailed:\n",
        "    p_value = 2 * (1 - Phi(abs(z_obs)))\n",
        "else:\n",
        "    p_value = 1 - Phi(z_obs)\n",
        "\n",
        "# Rango y densidad\n",
        "x = np.linspace(-4, 4, 800)\n",
        "y = phi(x)\n",
        "\n",
        "# Figura\n",
        "fig, ax = plt.subplots(figsize=(8, 5))\n",
        "\n",
        "# Curva de densidad\n",
        "ax.plot(x, y, label=\"Densidad N(0,1)\")\n",
        "\n",
        "# Sombreado de la(s) cola(s)\n",
        "if two_tailed:\n",
        "    mask_left = x <= -abs(z_obs)\n",
        "    mask_right = x >= abs(z_obs)\n",
        "    ax.fill_between(x, 0, y, where=mask_left, alpha=0.4, label=\"Región del p-value\")\n",
        "    ax.fill_between(x, 0, y, where=mask_right, alpha=0.4)\n",
        "    ax.axvline(-abs(z_obs), linestyle=\"--\")\n",
        "    ax.axvline(abs(z_obs), linestyle=\"--\")\n",
        "else:\n",
        "    mask_right = x >= z_obs\n",
        "    ax.fill_between(x, 0, y, where=mask_right, alpha=0.4, label=\"Región del p-value\")\n",
        "    ax.axvline(z_obs, linestyle=\"--\")\n",
        "\n",
        "# Anotaciones\n",
        "ax.set_title(\"Representación del p-value en una prueba z (dos colas)\")\n",
        "ax.set_xlabel(\"Estadístico Z\")\n",
        "ax.set_ylabel(\"Densidad\")\n",
        "\n",
        "texto = [\n",
        "    \"Definición: p = P(resultado igual o más extremo | H0)\",\n",
        "    f\"Estadístico observado: Z = {z_obs:.2f}\",\n",
        "    f\"p-value (dos colas): {p_value:.4f}\"\n",
        "]\n",
        "ax.text(0.02, 0.95, \"\\n\".join(texto), transform=ax.transAxes, va=\"top\")\n",
        "\n",
        "ax.legend(loc=\"upper right\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Intervalos de confianza\n",
        "\n",
        "Un **intervalo de confianza (IC)** es un **rango de valores** calculado a partir de una muestra que se utiliza para **estimar un parámetro desconocido** de la población (como la media o la proporción).\n",
        "\n",
        "Representa la **incertidumbre** asociada a una estimación muestral: no da un único valor, sino un intervalo dentro del cual se espera que esté el verdadero parámetro poblacional.\n",
        "\n",
        "* Una muestra proporciona una **estimación puntual** (por ejemplo, la media muestral $\\bar{X}$).\n",
        "* Sin embargo, debido al **muestreo aleatorio**, esa estimación **varía** entre muestras.\n",
        "* El intervalo de confianza incorpora esta variabilidad y nos indica **cuán precisas son nuestras estimaciones**.\n",
        "\n",
        "### Forma general del intervalo\n",
        "\n",
        "$ \\text{IC} = \\hat{\\theta} \\pm ( \\text{valor crítico} ) \\times ( \\text{error estándar} ) $\n",
        "\n",
        "donde:\n",
        "\n",
        "* $\\hat{\\theta}$ es el estimador muestral (por ejemplo, $\\bar{X}$),\n",
        "* el **valor crítico** proviene de una distribución estadística (normal o t),\n",
        "  - depende del rango del intervalo que queremos\n",
        "* el **error estándar** mide la variabilidad de la estimación.\n",
        "  - $ SE = s / \\sqrt{n} $\n",
        "\n",
        "### Interpretación\n",
        "\n",
        "* Un **intervalo de confianza del 95%** significa que, si repitiéramos el experimento muchas veces,\n",
        "  **el 95% de los intervalos construidos contendrían el valor real del parámetro**.\n",
        "* No significa que haya un 95% de probabilidad de que el parámetro esté dentro del intervalo —\n",
        "  el parámetro es fijo; la variabilidad está en las muestras.\n",
        "\n",
        "### Ejemplo\n",
        "\n",
        "Para una media muestral de $\\bar{X} = 10$, error estándar $= 0.5$ y un nivel de confianza del 95%:\n",
        "\n",
        "$ IC_{95\\%} = 10 \\pm 1.96 \\times 0.5 = [9.02, 10.98] $\n",
        "\n",
        "Interpretación: con un 95% de confianza, el valor medio poblacional se encuentra entre 9.02 y 10.98.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from matplotlib.patches import FancyArrowPatch\n",
        "import scipy.stats as st\n",
        "\n",
        "normal_sample = st.norm.rvs(10, 2, 100)\n",
        "\n",
        "interval = st.t.interval(\n",
        "    confidence = 0.95,\n",
        "    df = len(normal_sample) - 1,\n",
        "    loc = normal_sample.mean(),\n",
        "    scale = normal_sample.std() / math.sqrt(df)\n",
        ")\n",
        "print(f\"El intervalo es: {interval}\")\n",
        "\n",
        "interval2 = (\n",
        "    normal_sample.mean() + st.t.ppf(0.025, 9) * (normal_sample.std()/math.sqrt(9)),\n",
        "    normal_sample.mean() - st.t.ppf(0.025, 9) * (normal_sample.std()/math.sqrt(9))\n",
        ")\n",
        "print(f\"El intervalo es: {interval2}\")\n",
        "\n",
        "fig, axes = plt.subplots()\n",
        "axes.hist(normal_sample, 5)\n",
        "\n",
        "patch = FancyArrowPatch(\n",
        "    (interval[0], 40),\n",
        "    (interval[1], 40),\n",
        "    arrowstyle = \"|-|\",\n",
        "    mutation_scale = 10,\n",
        "    color = \"#FF0000\"\n",
        ")\n",
        "axes.add_patch(patch)\n",
        "fig.tight_layout()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Nivel de confianza\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import scipy.stats as st\n",
        "import numpy as np\n",
        "samples_1000 = pd.Series(np.zeros(1000)).apply(\n",
        "    st.norm.rvs,\n",
        "    size = 100\n",
        ")\n",
        "\n",
        "intervals = samples_1000.map(\n",
        "    lambda x: st.t.interval(\n",
        "        confidence = 0.95,\n",
        "        df = 99,\n",
        "        loc = x.mean(),\n",
        "        scale = st.sem(x)\n",
        "    )\n",
        ").explode().to_numpy().reshape((1000,2))\n",
        "\n",
        "success_ratio = (\n",
        "    (intervals.T[0] <= 0) & (intervals.T[1] >= 0)\n",
        ").sum() / 1000\n",
        "print(\n",
        "    f\"El {success_ratio*100:0.2f}% de las muestras tienen un \"\n",
        "    \"intervalo de confianza que contiene la media poblacional\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**los intervalos de confianza no se limitan a variables numéricas continuas**.\n",
        "\n",
        "También existen **análogos para variables categóricas**, pero en esos casos lo que se estima **no es una media**, sino una **proporción** .\n",
        "\n",
        "En una variable categórica, cada categoría puede representarse como una **proporción poblacional** $p$ (por ejemplo, “el 60% de las personas prefiere la opción A”).\n",
        "\n",
        "A partir de una muestra, se calcula una **proporción muestral** $\\hat{p}$ y se estima un **intervalo de confianza** para el valor poblacional de $p$.\n",
        "\n",
        "Por tanto, el **análogo del intervalo de confianza** para variables categóricas es el **intervalo de confianza para una proporción**.\n",
        "\n",
        "### Intervalo de confianza para una proporción\n",
        "\n",
        "Si $\\hat{p}$ es la proporción observada en una muestra de tamaño $n$, el intervalo de confianza del $100(1-\\alpha)%$ se estima como:\n",
        "\n",
        "$ IC = \\hat{p} \\pm z_{1 - \\alpha/2} \\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}} $\n",
        "\n",
        "donde:\n",
        "\n",
        "* $\\hat{p}$ = proporción muestral\n",
        "* $n$ = tamaño de muestra\n",
        "* $z_{1-\\alpha/2}$ = valor crítico de la distribución normal (por ejemplo, 1.96 para 95% de confianza)\n",
        "\n",
        "\n",
        "### Ejemplo\n",
        "\n",
        "Supongamos que en una encuesta de **100 personas**, **62 respondieron “sí”** a una pregunta.\n",
        "Entonces:\n",
        "\n",
        "$ \\hat{p} = \\frac{62}{100} = 0.62 $\n",
        "\n",
        "Con un nivel de confianza del 95%:\n",
        "\n",
        "$ IC_{95\\%} = 0.62 \\pm 1.96 \\sqrt{\\frac{0.62(1 - 0.62)}{100}} $\n",
        "$ IC_{95\\%} = 0.62 \\pm 0.094 $\n",
        "$ IC_{95\\%} = [0.526,\\ 0.714] $\n",
        "\n",
        "**Interpretación:** con un 95% de confianza, entre el 52.6% y el 71.4% de la población diría “sí”."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## Bootstrap\n",
        "\n",
        "El **método bootstrap** es una técnica **no paramétrica** de inferencia estadística que permite **estimar la variabilidad** de un estadístico (como la media, mediana o correlación) **a partir de los propios datos muestrales**, sin necesidad de conocer la distribución poblacional.\n",
        "\n",
        "En lugar de suponer una forma teórica de la población, el bootstrap **simula nuevas muestras** a partir de la muestra observada.\n",
        "\n",
        "* Aumenta la **robustez** de las conclusiones, ya que no depende de distribuciones teóricas.\n",
        "* Permite **inferir propiedades poblacionales** cuando los métodos analíticos clásicos no son aplicables o los supuestos (como normalidad) no se cumplen.\n",
        "\n",
        "### Idea fundamental\n",
        "\n",
        "1. Se toma una **muestra original** de tamaño $n$.\n",
        "2. Se generan **muestras bootstrap** del mismo tamaño $n$, **re-muestreando con reemplazo**.\n",
        "3. Para cada muestra, se calcula el **estadístico de interés** (por ejemplo, la media).\n",
        "4. La **distribución de los estadísticos obtenidos** sirve para estimar:\n",
        "\n",
        "   * La **variabilidad (error estándar)**,\n",
        "   * Los **intervalos de confianza**,\n",
        "   * La **forma de la distribución del estimador**.\n",
        "\n",
        "### Ventajas clave\n",
        "\n",
        "* No requiere conocer la distribución poblacional.\n",
        "* Aplicable a estadísticos complejos o no lineales.\n",
        "* Facilita la obtención de **intervalos de confianza empíricos**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "main_sample = st.norm.rvs(size=100)\n",
        "\n",
        "replicate = pd.Series(\n",
        "    [\n",
        "        np.random.choice(\n",
        "            main_sample,\n",
        "            size = 25\n",
        "        )\n",
        "        for _ in range(10000)\n",
        "    ]\n",
        ")\n",
        "means = replicate.apply(np.mean)\n",
        "plt.hist(means, bins = 20)\n",
        "interval = [\n",
        "    means.quantile(0.025),\n",
        "    means.quantile(0.975)\n",
        "]\n",
        "print(interval)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pruebas de ajuste de una muestra a una distribución.\n",
        "\n",
        "- Permite medir que tan verosimil es que una muestra haya sido obtenida\n",
        "  aleatoriamente de una distribución teórica dada.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
        "\n",
        "# Configuración general\n",
        "x = np.linspace(60, 140, 400)\n",
        "\n",
        "# 1. Comparar una muestra con una población\n",
        "mu_pop, sigma_pop = 100, 10\n",
        "\n",
        "y_pop = norm.pdf(x, mu_pop, sigma_pop)\n",
        "y_samp = norm.rvs(mu_pop, sigma_pop, 100)\n",
        "\n",
        "fig, ax = plt.subplots(1, 1, figsize=(9, 4))\n",
        "\n",
        "# --- Gráfico 1: muestra vs población ---\n",
        "ax.plot(x, y_pop, label='Población (μ=100)', linewidth=2)\n",
        "ax.axvline(mu_pop, color='C0', linestyle=':')\n",
        "ax.set_title(\"Comparar una muestra con una población\")\n",
        "ax.set_xlabel(\"Variable\")\n",
        "ax.set_ylabel(\"Densidad\")\n",
        "ax.legend()\n",
        "\n",
        "\n",
        "inset = inset_axes(ax, width=\"30%\", height=\"50%\", loc=\"upper right\")\n",
        "inset.hist(y_samp, color='C0', linewidth=2)\n",
        "\n",
        "ax.annotate(\n",
        "  text=\"Muestra\",\n",
        "  xy=(110, 0.008),\n",
        "  xytext=(127, 0.013),\n",
        "  arrowprops={\"arrowstyle\": \"->\"}\n",
        ")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test de T de Student para una muestra\n",
        "\n",
        "- Permite evaluar si\n",
        "  - la media de una muestra es diferente de una media $\\mu_0$.\n",
        "- El uso del test supone:\n",
        "  - Distribución normal de la variable (continua) en la población\n",
        "  - Muestreo al azar (cada observación es independiente)\n",
        "- El estadístico $t$ sigue una distribución *T de Student* con $n - 1$ grados de libertad.\n",
        "\n",
        "$ t =  (\\bar{x} - \\mu ) / { \\frac{s}{\\sqrt{n}} }$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Supongamos una variable aleatoria $X$ que en la población se distribuye con una\n",
        "distribución $N(0, 1)$.\n",
        "\n",
        "- Estamos interesados en apoyar la hipótesis de que la media de esa variable $X$\n",
        "  en la población es mayor a 0.\n",
        "  - $H_0 : \\mu = 0$\n",
        "  - $H_1 : \\mu > 0$\n",
        "- el *p value* para un valor observado $T$ será:\n",
        "  - $P(t \\ge T|H_0)$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import scipy.stats as st\n",
        "import math\n",
        "\n",
        "normal_sample = st.norm.rvs(size = 10, loc=1.0)\n",
        "df = len(normal_sample) - 1 # 9\n",
        "\n",
        "# Calculando a mano\n",
        "t_value = (normal_sample.mean() - 0) / (normal_sample.std()/math.sqrt(df))\n",
        "# t_value\n",
        "pvalue = 1 - st.t.cdf(t_value, df)\n",
        "print(f\"El valor del estadístico T es {t_value}\")\n",
        "print(f\"El p-valor es {pvalue}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "x = np.linspace(-4, 4, 100)\n",
        "\n",
        "plt.plot(x, st.t.pdf(x, df))\n",
        "\n",
        "x_fill = np.linspace(t_value, 4, 100)\n",
        "plt.fill_between(\n",
        "    x_fill,\n",
        "    st.t.pdf(x_fill, df),\n",
        "    color=\"lightblue\"\n",
        ")\n",
        "\n",
        "plt.annotate(\n",
        "    xy = ((4+t_value)/2, st.t.pdf((4+t_value)/2, df)/2),\n",
        "    xytext = (1, 0.38),\n",
        "    text = f\"p-valor = 1 - $CDF_T(t) = {1-st.t.cdf(t_value, df):0.3f}$\",\n",
        "    arrowprops = {\n",
        "        \"arrowstyle\":\"->\"\n",
        "    }\n",
        ")\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Usando scipy\n",
        "test_result = st.ttest_1samp(\n",
        "    normal_sample,\n",
        "    popmean=0,\n",
        "    alternative=\"greater\",\n",
        ")\n",
        "test_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Podemos definir diferentes hipótesis alternativas:\n",
        "- Es necesario cambiar la definición del *valor P* para estos casos:\n",
        "  - $H_1 > 0$ (Una cola, mayor)\n",
        "    - $p_{value} = 1 - CDF_T(t)$\n",
        "    - El ejemplo anterior\n",
        "  - $H_1 < 0$ (Una cola, menor)\n",
        "    - $p_{value} = CDF_T(t)$\n",
        "  - $H_a \\ne 0$ (dos colas)\n",
        "    - $p_{value} = 2 \\times min(CDF_T(t), 1-CDF_T(t))$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En el caso del test de dos colas:\n",
        "- Parece evidente:\n",
        "  - multiplicar por dos al de menor de los p-valores las colas.\n",
        "- Esto es por la simetría de la distribución.\n",
        "- En distribuciones asimétricas, no es evidente que hacer:\n",
        "  - En general se toma la idea de doblar el p-valor menor.\n",
        "\n",
        "En particular, para una variable aleatoria $X$, que sigue una determinada\n",
        "distribución si $H_0$ es cierta, dado un estimador $x_0$, el *p value* es:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "one_tail_greater = 1 - st.t.cdf(t_value, df)\n",
        "one_tail_lower = st.t.cdf(t_value, df)\n",
        "\n",
        "two_tails = 2 * min(one_tail_greater, one_tail_lower)\n",
        "print(f\"El pvalue de una cola, mayor es {one_tail_greater}\")\n",
        "print(f\"El pvalue de una cola, menor es {one_tail_lower}\")\n",
        "print(f\"El pvalue de dis colas es {two_tails}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "one_tail_greater = st.ttest_1samp(normal_sample, popmean = 0, alternative = \"greater\")\n",
        "one_tail_lower = st.ttest_1samp(normal_sample, popmean = 0, alternative = \"less\")\n",
        "two_tails = st.ttest_1samp(normal_sample, popmean = 0, alternative = \"two-sided\")\n",
        "print(f\"El pvalue de una cola, mayor es {one_tail_greater.pvalue}\")\n",
        "print(f\"El pvalue de una cola, menor es {one_tail_lower.pvalue}\")\n",
        "print(f\"El pvalue de dis colas es {two_tails.pvalue}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "x = np.linspace(-5, 5, 100)\n",
        "x1 = np.linspace(2, 5, 100)\n",
        "x2 = np.linspace(-5, 2, 100)\n",
        "x3 = np.linspace(-5, -2, 100)\n",
        "\n",
        "fig, axes = plt.subplots(figsize = (6, 9), nrows = 3)\n",
        "\n",
        "axes[0].plot(x, st.t.pdf(x, 9))\n",
        "axes[0].fill_between(x1, st.t.pdf(x1, 9), color=\"lightblue\")\n",
        "axes[0].set_title(\"Una cola (mayor)\")\n",
        "\n",
        "axes[1].plot(x, st.t.pdf(x, 9))\n",
        "axes[1].fill_between(x3, st.t.pdf(x3, 9), color=\"lightblue\")\n",
        "axes[1].set_title(\"Una cola (menor)\")\n",
        "\n",
        "axes[2].plot(x, st.t.pdf(x, 9))\n",
        "axes[2].fill_between(x3, st.t.pdf(x3, 9), color=\"lightblue\")\n",
        "axes[2].fill_between(x1, st.t.pdf(x1, 9), color=\"lightblue\")\n",
        "axes[2].set_title(\"Dos colas\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBxiOQVSv-Wy"
      },
      "source": [
        "\n",
        "### Prueba χ²\n",
        "\n",
        "Se puede utilizar para testear la bondad de ajuste de:\n",
        "- cualquier distribución univariada\n",
        "  - para la cual se pueda calcular la *CDF*.\n",
        "- Requiere datos en grupos\n",
        "  - Para poder utilizar el test en una distribución continua\n",
        "    debemos discretizar los datos (como en un histograma)\n",
        "- Es sensible a la elección de los bins.\n",
        "- El tamaño muestral debe ser relativamente grande.\n",
        "- $ χ^{2} = \\sum_{i=1}^{k}{\\frac{(O_i - E_i)^{2}}{E_i}} $\n",
        "- Es necesario indicar los grados de libertad.\n",
        "  - número de categorías que pueden variar libremente en un análisis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "Mt5sYdqvv-Wy",
        "outputId": "a550a49a-c47b-40d2-e1fc-414cbb8fd745"
      },
      "outputs": [],
      "source": [
        "import scipy.stats as st\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "observed = st.binom.rvs(n=10, p=0.2, size = 100)\n",
        "\n",
        "values = np.unique(observed)\n",
        "values.sort()\n",
        "mval = max(values)\n",
        "\n",
        "_ = plt.hist(\n",
        "  observed,\n",
        "  bins = range(mval+1),\n",
        "  width = 1,\n",
        "  align = \"left\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyA6kIIzv-Wz",
        "outputId": "82a2b7a5-fb72-40a5-f741-eeedfba337fd"
      },
      "outputs": [],
      "source": [
        "obs_cdf = st.cumfreq(\n",
        "  observed,\n",
        "  numbins=mval+1,\n",
        "  defaultreallimits = (0, mval)\n",
        ").cumcount\n",
        "\n",
        "teoretical_cdf = st.binom.cdf(\n",
        "  np.arange(mval+1),\n",
        "  n=10,\n",
        "  p=0.2\n",
        ")\n",
        "\n",
        "teoretical_cdf = teoretical_cdf * sum(obs_cdf) / sum (teoretical_cdf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots()\n",
        "\n",
        "axes.bar(np.arange(mval+1)-0.2, obs_cdf, width = 0.3, label = \"observed\")\n",
        "axes.bar(np.arange(mval+1)+0.2, teoretical_cdf, width = 0.3, label = \"theoretical\")\n",
        "\n",
        "for x, y in zip(np.arange(mval+1)-0.2, obs_cdf):\n",
        "  axes.text(x, y+1, f\"{y:0.0f}\", ha=\"center\")\n",
        "for x, y in zip(np.arange(mval+1)+0.2, teoretical_cdf):\n",
        "  axes.text(x, y+1, f\"{y:0.1f}\", ha=\"center\")\n",
        "\n",
        "_ = axes.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpjdc3s2v-Wz",
        "outputId": "91cdc896-be34-46f1-8da0-b80bd03994ff"
      },
      "outputs": [],
      "source": [
        "resultado = st.chisquare(\n",
        "  f_obs=obs_cdf,\n",
        "  f_exp=teoretical_cdf\n",
        ")\n",
        "\n",
        "axes.set_title(f\"El p-value del test es: {resultado.pvalue:0.3f}\")\n",
        "fig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-MKke7ov-Wz"
      },
      "source": [
        "### Prueba de Kolmogórov-Smirnov\n",
        "\n",
        "- Usa la función de densidad acumulada (*CDF*).\n",
        "- Hipótesis Nula y Alternativa:\n",
        "  - Hipótesis Nula (H0): La muestra sigue la distribución teórica propuesta.\n",
        "  - Hipótesis Alternativa (H1): La muestra no sigue la distribución teórica propuesta.\n",
        "- Su estadístico, $D$:\n",
        "  - mide la distancia entre:\n",
        "    - la *CDF* de la distribución de la hipótesis nula,\n",
        "    - y la *CDF* de la muestra.\n",
        "  - Es el valor máximo de las diferencias.\n",
        "  - $D=0$ si ambas distribuciones acumuladas son idénticas.\n",
        "- La distribución nula debe ser **continua**.\n",
        "- No tiene gran poder\n",
        "  - puede requerir un tamaño muestral grande para rechazar la hipótesis nula."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0on3QJgmv-Wz",
        "outputId": "a8ecb31c-693a-47d3-8785-5a5ec39626d1"
      },
      "outputs": [],
      "source": [
        "import scipy.stats as st\n",
        "\n",
        "sample_size = 100\n",
        "sample_one = st.norm.rvs(size=sample_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample_one_ecdf_x = sample_one.copy()\n",
        "sample_one_ecdf_x.sort()\n",
        "sample_one_ecdf_y = np.arange(sample_size)/sample_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "normal_cdf_y = st.norm.cdf(sample_one_ecdf_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots()\n",
        "\n",
        "max_diff_index = np.argmax(np.abs(sample_one_ecdf_y - normal_cdf_y))\n",
        "\n",
        "for i, (x, y1, y2) in enumerate(zip(sample_one_ecdf_x, sample_one_ecdf_y, normal_cdf_y)):\n",
        "  color = \"gray\" if i != max_diff_index else \"red\"\n",
        "  lwd = 1  if i != max_diff_index else 2\n",
        "  axes.plot([x, x], [y1, y2], color=color, linewidth = lwd)\n",
        "\n",
        "axes.plot(\n",
        "  sample_one_ecdf_x,\n",
        "  sample_one_ecdf_y,\n",
        "  label = \"Empirical sample CDF\"\n",
        ")\n",
        "axes.plot(\n",
        "  sample_one_ecdf_x,\n",
        "  normal_cdf_y,\n",
        "  label = \"Normal Distribution CDF\"\n",
        "  )\n",
        "\n",
        "_ = axes.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "st.kstest(sample_one, st.norm.cdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RG4wvDC0v-Wz"
      },
      "source": [
        "## Comparación de dos muestras - Tests de forma"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccPv7ZRMv-W0"
      },
      "source": [
        "### Test de Kolmogorov-Smirnov\n",
        "\n",
        "El **test de Kolmogorov–Smirnov de dos muestras (KS de dos muestras)** sirve\n",
        "para responder una pregunta simple:\n",
        "\n",
        "“¿Provienen dos conjuntos de datos de la misma distribución?”\n",
        "\n",
        "El test **compara las funciones de distribución acumulada (CDF)** de las dos\n",
        "muestras.\n",
        "\n",
        "Cada muestra genera una curva que dice “cuánto porcentaje de los datos está por\n",
        "debajo de un cierto valor”.\n",
        "\n",
        "* Si ambas curvas son casi iguales, entonces las dos muestras podrían venir de\n",
        "  la misma distribución.\n",
        "* Si las curvas se separan mucho, probablemente las muestras vienen de\n",
        "  distribuciones distintas.\n",
        "\n",
        "\n",
        "#### Estadístico: diferencia máxima\n",
        "\n",
        "El **estadístico KS** se llama $D$, y se define como:\n",
        "\n",
        "$$ D = \\max_x |F_1(x) - F_2(x)| $$\n",
        "\n",
        "donde:\n",
        "\n",
        "* $F_1(x)$ es la CDF empírica de la muestra 1,\n",
        "* $F_2(x)$ es la CDF empírica de la muestra 2.\n",
        "\n",
        "$D$ mide la **mayor diferencia vertical** entre las dos curvas acumuladas.\n",
        "\n",
        "* Si $D$ es **pequeño**, las curvas están muy cerca: las distribuciones parecen\n",
        "  similares.\n",
        "* Si $D$ es **grande**, hay una diferencia marcada en algún punto: las\n",
        "  distribuciones parecen distintas.\n",
        "\n",
        "#### Test\n",
        "\n",
        "El test evalúa cuán grande tiene que ser $D$ para que esa diferencia **no pueda\n",
        "explicarse solo por el azar**.\n",
        "\n",
        "Bajo la **hipótesis nula** ($H_0$): las dos muestras provienen de la misma\n",
        "distribución. El test usa teoría de probabilidad (basada en el proceso de\n",
        "Kolmogorov) para calcular la **probabilidad de observar un $D$ igual o mayor**\n",
        "al encontrado si $H_0$ fuera cierta.\n",
        "\n",
        "Si esa probabilidad (el **p-valor**) es baja, rechazamos $H_0$.\n",
        "\n",
        "#### Ventajas\n",
        "\n",
        "* **No paramétrico:** no asume una forma específica de distribución (normal,\n",
        "  exponencial, etc.).\n",
        "* **Sensibilidad global:** detecta diferencias en posición, forma y dispersión,\n",
        "  no solo en la media.\n",
        "* **Basado solo en orden:** usa los valores ordenados, lo que lo hace robusto.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uMbmZvnv-W0",
        "outputId": "85a08ac0-1bcf-4efe-b3e0-60887d514b71"
      },
      "outputs": [],
      "source": [
        "import scipy.stats as st\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import bisect\n",
        "\n",
        "def ecdf(values) -> tuple[list[float], list[float]]:\n",
        "  ejex = values.copy()\n",
        "  ejex.sort()\n",
        "  ejey = np.arange(len(values)) / len(values)\n",
        "  return (ejex, ejey.tolist())\n",
        "\n",
        "def find_closest(x, data):\n",
        "  pos = bisect.bisect_left(data, x)\n",
        "  if pos == 0:\n",
        "      nearest = pos\n",
        "  elif pos == len(data):\n",
        "      nearest = pos - 1\n",
        "  else:\n",
        "      before = pos - 1\n",
        "      after = pos\n",
        "      nearest = before if abs(x - before) < abs(x - after) else after\n",
        "  return nearest\n",
        "\n",
        "def find_max_diff(xs1, ys1, xs2, ys2):\n",
        "  max = 0\n",
        "  max_p = (None, None, None)\n",
        "  for x, y in zip(xs1, ys1):\n",
        "    n = find_closest(x, xs2)\n",
        "    d = ys2[n] - y\n",
        "    if abs(d) > max:\n",
        "      max = abs(d)\n",
        "      max_p = (x, y, ys2[n])\n",
        "  return max_p\n",
        "\n",
        "sample_one = st.norm.rvs(size=50)\n",
        "sample_two = st.norm.rvs(size=50)\n",
        "sample_three = st.t.rvs(1, size=50)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize= (12,5))\n",
        "\n",
        "s1_x, s1_y = ecdf(sample_one)\n",
        "s2_x, s2_y = ecdf(sample_two)\n",
        "s3_x, s3_y = ecdf(sample_three)\n",
        "\n",
        "max_x, max_d1, max_d2, = find_max_diff(s1_x, s1_y, s2_x, s2_y)\n",
        "axes[0].plot(s1_x, s1_y)\n",
        "axes[0].plot(s2_x, s2_y)\n",
        "axes[0].set_xlim(-4, 4)\n",
        "axes[0].plot([max_x, max_x], [max_d1, max_d2])\n",
        "axes[0].set_title(\"Sample 1 vs Sample 2\")\n",
        "\n",
        "max_x, max_d1, max_d3, = find_max_diff(s1_x, s1_y, s3_x, s3_y)\n",
        "axes[1].plot(s1_x, s1_y)\n",
        "axes[1].plot(s3_x, s3_y)\n",
        "axes[1].set_xlim(-4, 4)\n",
        "axes[1].plot([max_x, max_x], [max_d1, max_d3])\n",
        "axes[1].set_title(\"Sample 1 vs Sample 2\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "same_dist_res = st.kstest(sample_one, sample_two)\n",
        "print(f\"El pvalue para dos muestras de la misma población es:\", same_dist_res)\n",
        "diff_dist_res = st.kstest(sample_one, sample_three)\n",
        "print(\n",
        "    f\"El pvalue para dos muestras de diferentes poblaciones es:\",\n",
        "    diff_dist_res\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gy7LEJMsv-W0"
      },
      "source": [
        "### Test $\\chi^2$\n",
        "\n",
        "El **test $\\chi^2$** se usa para comparar **frecuencias observadas** con\n",
        "**frecuencias esperadas**. En el caso de **dos muestras o dos variables\n",
        "categóricas**, la idea es:\n",
        "\n",
        "“¿Las dos muestras (o variables) muestran la misma distribución de categorías, o\n",
        "son diferentes?”\n",
        "\n",
        "Por ejemplo:\n",
        "\n",
        "* ¿La proporción de hombres y mujeres es igual entre dos grupos distintos?\n",
        "* ¿El resultado de un examen (aprobado/suspendido) depende del tipo de curso (A\n",
        "  o B)?\n",
        "\n",
        "#### Cómo se estructura el problema\n",
        "\n",
        "Se representa la información en una **tabla de contingencia**:\n",
        "\n",
        "| Categoría | Muestra 1 | Muestra 2 | Total |\n",
        "| --------- | --------- | --------- | ----- |\n",
        "| A         | 30        | 20        | 50    |\n",
        "| B         | 10        | 20        | 30    |\n",
        "| Total     | 40        | 40        | 80    |\n",
        "\n",
        "¿La distribución entre A y B es la misma en las dos muestras?\n",
        "\n",
        "#### Qué espera el test bajo la hipótesis nula\n",
        "\n",
        "La **hipótesis nula ($H_0$)** dice:\n",
        "\n",
        "Las dos muestras provienen de la **misma distribución** de categorías. Es decir,\n",
        "no hay relación entre muestra y categoría.\n",
        "\n",
        "Bajo $H_0$, las frecuencias esperadas se calculan asumiendo **independencia**\n",
        "entre las filas y las columnas. La frecuencia esperada para una celda $(i, j)$\n",
        "es:\n",
        "\n",
        "$$ E_{ij} = \\frac{(\\text{total fila } i) \\times (\\text{total columna }\n",
        "j)}{\\text{total general}} $$\n",
        "\n",
        "Por ejemplo, en la tabla anterior:\n",
        "\n",
        "* Esperado en la celda (A, Muestra 1) sería $E_{A,1} = \\frac{50 \\times 40}{80} =\n",
        "  25$.\n",
        "\n",
        "#### Cómo mide la diferencia\n",
        "\n",
        "El estadístico chi-cuadrado mide **cuánto se alejan las frecuencias observadas\n",
        "de las esperadas**, ponderando la desviación por la magnitud esperada:\n",
        "\n",
        "$$ \\chi^2 = \\sum_{i,j} \\frac{(O_{ij} - E_{ij})^2}{E_{ij}} $$\n",
        "\n",
        "* Si las diferencias $O_{ij} - E_{ij}$ son pequeñas (las observaciones se\n",
        "  parecen a lo esperado), $\\chi^2$ será pequeño.\n",
        "* Si hay celdas con diferencias grandes, $\\chi^2$ será grande.\n",
        "\n",
        "Bajo $H_0$, el valor de $\\chi^2$ **sigue aproximadamente una distribución\n",
        "chi-cuadrado** con un cierto número de **grados de libertad**:\n",
        "\n",
        "$$ \\text{gl} = (\\text{número de filas} - 1) \\times (\\text{número de columnas} -\n",
        "1) $$\n",
        "\n",
        "El **p-valor** es la probabilidad de observar un valor de $\\chi^2$ tan grande o\n",
        "mayor que el obtenido si $H_0$ fuera cierta.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJbnORa1v-W0",
        "outputId": "49fcf5a4-a4c6-4cbf-973e-2d0fdd655779"
      },
      "outputs": [],
      "source": [
        "# Genero las muestras\n",
        "sample_one = st.norm.rvs(size=100)\n",
        "sample_two = st.norm.rvs(size=100)\n",
        "# Agrupo los datos en categorias\n",
        "maxval = np.concatenate((sample_one, sample_two)).max()\n",
        "minval = np.concatenate((sample_one, sample_two)).min()\n",
        "s1hist = np.histogram(sample_one, bins=5, range=(minval, maxval))\n",
        "s2hist = np.histogram(sample_two, bins=5, range=(minval, maxval))\n",
        "print(\n",
        "    f\"El primer grupo es: {s1hist[0]}\\n\",\n",
        "    f\"El segundo grupo es: {s2hist[0]}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERM3vLaHv-W0",
        "outputId": "372a2da8-006e-45cc-ae9e-5cee9b83aeea"
      },
      "outputs": [],
      "source": [
        "# Calculo las frecuencias esperadas:\n",
        "fexp = (s1hist[0] + s2hist[0])/2\n",
        "fexp = np.array([fexp, fexp])\n",
        "\n",
        "# Genero un array 2D con los datos observados\n",
        "fobs = np.array([s1hist[0], s2hist[0]])\n",
        "\n",
        "print(f\"Las frecuencias esperadas son:\\n{fexp}\\n\")\n",
        "print(f\"Los datos observados son:\\n{fobs}\\n\")\n",
        "dof = len(fobs[0])-1\n",
        "print(f\"Los grados de libertad son: {dof}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pl_LNgaIv-W1",
        "outputId": "cb787644-4863-4897-98e9-6e41de04bb45"
      },
      "outputs": [],
      "source": [
        "st.chisquare(\n",
        "    f_obs = fobs.ravel(),\n",
        "    f_exp = fexp.ravel(),\n",
        "    ddof = fobs.size - 1 - dof\n",
        ")\n",
        "\n",
        "# DOFcomputed = size - 1 - ddof = size - 1 - (size - 1 - dof) =>\n",
        "# DOFcomputed = dof"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oans_-b_v-W1"
      },
      "source": [
        "Otra opción es usar tablas de contigencia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCA589mTv-W1",
        "outputId": "d01105ce-29d5-4a50-cc35-982855cc7c93"
      },
      "outputs": [],
      "source": [
        "chi2, p, dof, ex = st.chi2_contingency(fobs)\n",
        "print(chi2, p, dof, ex)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VGqFkyOv-W1"
      },
      "source": [
        "Usando tablas de contingencia podemos comparar distribuciones de variables\n",
        "categóricas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "cxQZtd7Gv-W1",
        "outputId": "4aa7f7cb-f3a8-4f2b-e42a-6a1c5d87e489"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from time import time_ns, sleep\n",
        "marcas = [\"MarcaA\", \"MarcaB\", \"MarcaC\", \"MarcaD\", \"MarcaE\"]\n",
        "\n",
        "grupos = [\n",
        "    \"Niños\",\n",
        "    \"Jovenes\",\n",
        "    \"Adultos\"\n",
        "]\n",
        "\n",
        "sample_size = 50\n",
        "data = []\n",
        "for g in grupos:\n",
        "    # np.random.seed(3)\n",
        "    freqs = np.random.uniform(size=len(marcas))\n",
        "    freqs = freqs/freqs.sum()\n",
        "    sample_summary = st.multinomial.rvs(\n",
        "        sample_size,\n",
        "        freqs,\n",
        "        1,\n",
        "        random_state = time_ns() % 323\n",
        "    ).squeeze()\n",
        "    data.append(sample_summary)\n",
        "data = np.array(data)\n",
        "data.T\n",
        "data = pd.DataFrame(\n",
        "    data = data,\n",
        "    index = grupos,\n",
        "    columns = marcas\n",
        ")\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9T58Rnjv-W2",
        "outputId": "0c708e5d-e838-40ed-d51f-0a32e59580e0"
      },
      "outputs": [],
      "source": [
        "chi2, pval, dof, ex = st.contingency.chi2_contingency(data)\n",
        "print(f\"El pvalue es {pval}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test de Fisher (Fisher's Exact Test)\n",
        "\n",
        "* Prueba estadística para evaluar si existe una **asociación significativa** entre dos variables **categóricas nominales**.\n",
        "* Se emplea cuando el **test $\\chi^2$ no es adecuado**, especialmente cuando:\n",
        "\n",
        "  * Las **frecuencias esperadas** en una o más celdas son **menores que 5**.\n",
        "  * El **tamaño muestral es pequeño**.\n",
        "* Se utiliza en tablas de **contingencia $2\\times2$**, comparando:\n",
        "\n",
        "  * **Dos grupos** o condiciones.\n",
        "  * **Dos categorías** por variable.\n",
        "* Calcula la **probabilidad exacta** de obtener la tabla observada (o más extrema), bajo la hipótesis nula de **independencia**.\n",
        "* Es un método **no aproximado**, por lo que resulta más preciso en escenarios con pocos datos.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Si las dos variables fueran totalmente independientes, qué tan probable sería obtener una tabla como la que observamos, o incluso más extrema?**\n",
        "\n",
        "\n",
        "La probabilidad exacta proviene de la distribución hipergeométrica\n",
        "\n",
        "* Sacas un número fijo de elementos sin reemplazo.\n",
        "* La distribución del número de éxitos que caen en una categoría sigue una **distribución hipergeométrica**.\n",
        "\n",
        "- El Test de Fisher **calcula esa probabilidad exacta** para la tabla observada.\n",
        "- Después suma las probabilidades de todas las tablas \"tan extremas o más extremas\"\n",
        "\n",
        "**más alejadas de lo que esperaría la independencia.**\n",
        "\n",
        "* Se calcula la probabilidad de la tabla observada.\n",
        "* Luego la probabilidad de todas las tablas posibles con igual o mayor evidencia de asociación.\n",
        "* La suma de esas probabilidades es el **valor p**.\n",
        "\n",
        "No usa aproximaciones: por eso es confiable con pocos datos\n",
        "\n",
        "A diferencia del test $\\chi^2$:\n",
        "\n",
        "* No necesita aproximar nada con distribuciones continuas.\n",
        "* No depende de tamaños grandes.\n",
        "* Simplemente **enumera todas las posibilidades exactas** y calcula probabilidades exactas.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ejemplo numérico del Test de Fisher\n",
        "\n",
        "Supongamos que queremos saber si un **tratamiento** (T) está asociado con **mejoría** (M).\n",
        "Tenemos una tabla $2\\times2$ con pocos datos:\n",
        "\n",
        "|                 | Mejoró (Sí) | No mejoró (No) | Total  |\n",
        "| --------------- | ----------- | -------------- | ------ |\n",
        "| Tratamiento (T) | 4           | 1              | 5      |\n",
        "| Control (C)     | 1           | 4              | 5      |\n",
        "| **Total**       | **5**       | **5**          | **10** |\n",
        "\n",
        "A simple vista el tratamiento parece funcionar mejor.\n",
        "Ahora veremos si esto **podría ser solo azar**.\n",
        "\n",
        "#### Fijamos los totales\n",
        "\n",
        "* 5 personas recibieron tratamiento\n",
        "* 5 personas estuvieron en control\n",
        "* 5 personas mejoraron en total\n",
        "* 5 personas no mejoraron\n",
        "\n",
        "El Test de Fisher asume que **estos totales no cambian**.\n",
        "\n",
        "#### Modelo hipergeométrico\n",
        "\n",
        "De los 10 participantes:\n",
        "\n",
        "* Hay 5 “éxitos” (Mejoró)\n",
        "* Elegimos 5 personas para el grupo de tratamiento\n",
        "\n",
        "**¿Cuál es la probabilidad de que el grupo de tratamiento reciba justamente 4 mejoras y 1 no-mejora?**\n",
        "\n",
        "La fórmula hipergeométrica es:\n",
        "\n",
        "$ P(X = k)=\\frac{\\binom{M}{k}\\binom{N-M}{n-k}}{\\binom{N}{n}} $\n",
        "\n",
        "Donde:\n",
        "\n",
        "* ( M = 5 ) (mejoraron en total)\n",
        "* ( N = 10 ) (total)\n",
        "* ( n = 5 ) (grupo tratamiento)\n",
        "* ( k = 4 ) (mejoraron en tratamiento)\n",
        "\n",
        "#### Calculamos la probabilidad de la tabla observada\n",
        "\n",
        "$ P = \\frac{\\binom{5}{4}\\binom{5}{1}}{\\binom{10}{5}} $\n",
        "\n",
        "Ahora sustituimos:\n",
        "\n",
        "* $ \\binom{5}{4} = 5 $\n",
        "* $ \\binom{5}{1} = 5 $\n",
        "* $ \\binom{10}{5} = 252 $\n",
        "\n",
        "Entonces:\n",
        "\n",
        "$ P = \\frac{5 \\cdot 5}{252}=\\frac{25}{252}\\approx 0.099 $\n",
        "\n",
        "Esta es la probabilidad de obtener **exactamente esa tabla** por azar.\n",
        "\n",
        "#### Tablas “tan extremas o más extremas”\n",
        "\n",
        "La idea es:\n",
        "**¿Cuáles son los repartos aún más extremos que esta tabla?**\n",
        "\n",
        "Dado que solo importa cuántos “Mejoró” caen en el tratamiento, las opciones posibles son:\n",
        "\n",
        "* 5 mejoras en tratamiento (extremo a favor de T)\n",
        "* 4 mejoras en tratamiento (tabla observada)\n",
        "* 3 mejoras (menos extremo)\n",
        "* 2 mejoras (menos extremo)\n",
        "* 1 mejora (extremo en contra)\n",
        "\n",
        "Se suman las probabilidades de tablas **tan extremas como la observada**, es decir:\n",
        "\n",
        "* 5 mejoras en tratamiento\n",
        "* 4 mejoras en tratamiento (la observada)\n",
        "\n",
        "Calculamos 5 mejoras:\n",
        "\n",
        "$\n",
        "P(X=5)=\\frac{\\binom{5}{5}\\binom{5}{0}}{\\binom{10}{5}}\n",
        "=\\frac{1 \\cdot 1}{252}\n",
        "=\\frac{1}{252}\n",
        "\\approx 0.004\n",
        "$\n",
        "\n",
        "#### El valor p\n",
        "\n",
        "$\n",
        "p = P(X=4) + P(X=5)\n",
        "= \\frac{25}{252} + \\frac{1}{252}\n",
        "=\\frac{26}{252}\n",
        "\\approx 0.103\n",
        "$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "data = [\n",
        "    [\"old\", \"female\", \"advanced\"], [\"young\", \"female\", \"advanced\"],\n",
        "    [\"old\", \"male\", \"advanced\"], [\"old\", \"female\", \"stable\"],\n",
        "    [\"young\", \"male\", \"advanced\"], [\"old\", \"female\", \"advanced\"],\n",
        "    [\"old\", \"female\", \"advanced\"], [\"young\", \"male\", \"advanced\"],\n",
        "    [\"young\", \"male\", \"stable\"], [\"old\", \"male\", \"stable\"],\n",
        "    [\"young\", \"male\", \"stable\"], [\"young\", \"male\", \"stable\"],\n",
        "    [\"old\", \"male\", \"stable\"], [\"old\", \"male\", \"stable\"],\n",
        "    [\"old\", \"female\", \"advanced\"], [\"young\", \"male\", \"stable\"],\n",
        "    [\"old\", \"female\", \"stable\"], [\"old\", \"male\", \"advanced\"],\n",
        "    [\"young\", \"female\", \"advanced\"], [\"old\", \"female\", \"advanced\"],\n",
        "    [\"old\", \"male\", \"stable\"], [\"old\", \"male\", \"stable\"],\n",
        "    [\"young\", \"male\", \"stable\"], [\"old\", \"male\", \"advanced\"],\n",
        "    [\"old\", \"female\", \"advanced\"]\n",
        "]\n",
        "df = pd.DataFrame(\n",
        "    data,\n",
        "    columns = [\"age\", \"sex\", \"disease\"]\n",
        ")\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import scipy.stats as st\n",
        "\n",
        "elements, counts = st.contingency.crosstab(df[\"sex\"], df[\"disease\"])\n",
        "df_counts = pd.DataFrame(counts)\n",
        "df_counts.index = elements[0]\n",
        "df_counts.columns = elements[1]\n",
        "print(df_counts)\n",
        "\n",
        "odds_ratio, pvalue = st.fisher_exact(counts)\n",
        "print(odds_ratio, pvalue)\n",
        "\n",
        "# ¿Qué pasa con el sexo?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Ejercicios\n",
        "\n",
        "# Se tienen datos de un conjunto de pacientes que fueron tratados con dos drogas,\n",
        "# una ya aprobada y de uso corriente y otra novedosa. En esta etapa del análisis\n",
        "# no se quiere saber si la droga novedosa es efectiva sino si reduce las\n",
        "# reacciones adversas.\n",
        "# La drogra aprobada es lo producida por \"Nocturnis Pharma\" y la novedosa por\n",
        "# \"Oldergen Labs\".\n",
        "\n",
        "# ¿Qué tipo de tests puede usar para comparar estos datos?\n",
        "# Seleccione dos tests, compare el efecto de la droga y la aparición de reacciones\n",
        "# adversas a los 5, 10 y 20 días. Haga una comparación para cada ventana de\n",
        "# tiempo\n",
        "\n",
        "# Compare los métodos entre sí\n",
        "\n",
        "# Recomensaría usar la droga nueva en reemplazo de la vieja.\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "data = [\n",
        "    {\"id\":1,\"laboratorio\":\"Nocturnis Pharma\",\"edad\":45,\"sexo\":\"M\",\"reaccion_5dias\":\"No\",\"reaccion_10dias\":\"No\",\"reaccion_20dias\":\"Si\"},\n",
        "    {\"id\":2,\"laboratorio\":\"Nocturnis Pharma\",\"edad\":52,\"sexo\":\"F\",\"reaccion_5dias\":\"No\",\"reaccion_10dias\":\"No\",\"reaccion_20dias\":\"Si\"},\n",
        "    {\"id\":3,\"laboratorio\":\"Nocturnis Pharma\",\"edad\":38,\"sexo\":\"F\",\"reaccion_5dias\":\"No\",\"reaccion_10dias\":\"No\",\"reaccion_20dias\":\"Si\"},\n",
        "    {\"id\":4,\"laboratorio\":\"Nocturnis Pharma\",\"edad\":60,\"sexo\":\"M\",\"reaccion_5dias\":\"No\",\"reaccion_10dias\":\"No\",\"reaccion_20dias\":\"No\"},\n",
        "    {\"id\":5,\"laboratorio\":\"Nocturnis Pharma\",\"edad\":48,\"sexo\":\"F\",\"reaccion_5dias\":\"No\",\"reaccion_10dias\":\"No\",\"reaccion_20dias\":\"No\"},\n",
        "    {\"id\":6,\"laboratorio\":\"Nocturnis Pharma\",\"edad\":41,\"sexo\":\"F\",\"reaccion_5dias\":\"No\",\"reaccion_10dias\":\"No\",\"reaccion_20dias\":\"No\"},\n",
        "    {\"id\":7,\"laboratorio\":\"Nocturnis Pharma\",\"edad\":50,\"sexo\":\"M\",\"reaccion_5dias\":\"No\",\"reaccion_10dias\":\"No\",\"reaccion_20dias\":\"No\"},\n",
        "    {\"id\":8,\"laboratorio\":\"Nocturnis Pharma\",\"edad\":33,\"sexo\":\"M\",\"reaccion_5dias\":\"No\",\"reaccion_10dias\":\"No\",\"reaccion_20dias\":\"No\"},\n",
        "    {\"id\":9,\"laboratorio\":\"Nocturnis Pharma\",\"edad\":56,\"sexo\":\"F\",\"reaccion_5dias\":\"No\",\"reaccion_10dias\":\"No\",\"reaccion_20dias\":\"No\"},\n",
        "    {\"id\":10,\"laboratorio\":\"Nocturnis Pharma\",\"edad\":47,\"sexo\":\"F\",\"reaccion_5dias\":\"No\",\"reaccion_10dias\":\"No\",\"reaccion_20dias\":\"No\"},\n",
        "]\n",
        "\n",
        "# Resto de las filas\n",
        "data += [\n",
        "    {\"id\":i, \"laboratorio\":\"Nocturnis Pharma\", \"edad\":edad, \"sexo\":sexo,\n",
        "     \"reaccion_5dias\":\"No\", \"reaccion_10dias\":\"No\", \"reaccion_20dias\":\"No\"}\n",
        "    for i, edad, sexo in [\n",
        "        (11,52,\"M\"), (12,44,\"F\"), (13,39,\"M\"), (14,55,\"F\"), (15,46,\"M\"), (16,62,\"F\"),\n",
        "        (17,51,\"F\"), (18,42,\"M\"), (19,36,\"F\"), (20,58,\"M\"), (21,49,\"F\"), (22,37,\"M\"),\n",
        "        (23,43,\"M\"), (24,54,\"F\"), (25,61,\"M\"), (26,40,\"F\"), (27,53,\"F\"), (28,47,\"M\"),\n",
        "        (29,34,\"M\"), (30,59,\"F\"), (31,45,\"F\"), (32,33,\"F\"), (33,57,\"M\"), (34,48,\"M\"),\n",
        "        (35,38,\"F\"), (36,60,\"F\"), (37,52,\"M\"), (38,41,\"F\"), (39,50,\"F\"), (40,36,\"M\"),\n",
        "        (41,44,\"M\"), (42,55,\"F\"), (43,39,\"M\"), (44,58,\"F\"), (45,43,\"F\"), (46,35,\"M\"),\n",
        "        (47,49,\"M\"), (48,62,\"F\"), (49,51,\"M\"), (50,57,\"F\")\n",
        "    ]\n",
        "]\n",
        "\n",
        "# Filas de Oldergen Labs con reacciones progresivas\n",
        "data += [\n",
        "    {\"id\":51,\"laboratorio\":\"Oldergen Labs\",\"edad\":42,\"sexo\":\"F\",\"reaccion_5dias\":\"Si\",\"reaccion_10dias\":\"Si\",\"reaccion_20dias\":\"Si\"},\n",
        "    {\"id\":52,\"laboratorio\":\"Oldergen Labs\",\"edad\":55,\"sexo\":\"M\",\"reaccion_5dias\":\"Si\",\"reaccion_10dias\":\"Si\",\"reaccion_20dias\":\"Si\"},\n",
        "    {\"id\":53,\"laboratorio\":\"Oldergen Labs\",\"edad\":47,\"sexo\":\"F\",\"reaccion_5dias\":\"Si\",\"reaccion_10dias\":\"Si\",\"reaccion_20dias\":\"Si\"},\n",
        "    {\"id\":54,\"laboratorio\":\"Oldergen Labs\",\"edad\":33,\"sexo\":\"M\",\"reaccion_5dias\":\"No\",\"reaccion_10dias\":\"Si\",\"reaccion_20dias\":\"Si\"},\n",
        "    {\"id\":55,\"laboratorio\":\"Oldergen Labs\",\"edad\":49,\"sexo\":\"F\",\"reaccion_5dias\":\"No\",\"reaccion_10dias\":\"Si\",\"reaccion_20dias\":\"Si\"},\n",
        "    {\"id\":56,\"laboratorio\":\"Oldergen Labs\",\"edad\":61,\"sexo\":\"M\",\"reaccion_5dias\":\"No\",\"reaccion_10dias\":\"Si\",\"reaccion_20dias\":\"Si\"},\n",
        "    {\"id\":57,\"laboratorio\":\"Oldergen Labs\",\"edad\":45,\"sexo\":\"F\",\"reaccion_5dias\":\"No\",\"reaccion_10dias\":\"No\",\"reaccion_20dias\":\"Si\"},\n",
        "    {\"id\":58,\"laboratorio\":\"Oldergen Labs\",\"edad\":52,\"sexo\":\"F\",\"reaccion_5dias\":\"No\",\"reaccion_10dias\":\"No\",\"reaccion_20dias\":\"Si\"},\n",
        "    {\"id\":59,\"laboratorio\":\"Oldergen Labs\",\"edad\":38,\"sexo\":\"M\",\"reaccion_5dias\":\"No\",\"reaccion_10dias\":\"No\",\"reaccion_20dias\":\"Si\"},\n",
        "    {\"id\":60,\"laboratorio\":\"Oldergen Labs\",\"edad\":41,\"sexo\":\"F\",\"reaccion_5dias\":\"No\",\"reaccion_10dias\":\"No\",\"reaccion_20dias\":\"Si\"},\n",
        "]\n",
        "\n",
        "# Resto de Oldergen Labs (sin reacción)\n",
        "data += [\n",
        "    {\"id\":i, \"laboratorio\":\"Oldergen Labs\", \"edad\":edad, \"sexo\":sexo,\n",
        "     \"reaccion_5dias\":\"No\", \"reaccion_10dias\":\"No\", \"reaccion_20dias\":\"No\"}\n",
        "    for i, edad, sexo in [\n",
        "        (61,59,\"M\"), (62,48,\"F\"), (63,44,\"F\"), (64,36,\"M\"), (65,57,\"F\"),\n",
        "        (66,40,\"F\"), (67,53,\"M\"), (68,46,\"F\"), (69,60,\"M\"), (70,39,\"F\"),\n",
        "        (71,34,\"M\"), (72,58,\"F\"), (73,43,\"M\"), (74,37,\"F\"), (75,50,\"M\"),\n",
        "        (76,62,\"M\"), (77,51,\"F\"), (78,45,\"M\"), (79,33,\"F\"), (80,56,\"F\"),\n",
        "        (81,40,\"M\"), (82,49,\"F\"), (83,41,\"M\"), (84,36,\"F\"), (85,55,\"M\"),\n",
        "        (86,44,\"F\"), (87,52,\"M\"), (88,57,\"F\"), (89,39,\"M\"), (90,48,\"F\"),\n",
        "        (91,33,\"F\"), (92,61,\"M\"), (93,50,\"F\"), (94,47,\"M\"), (95,43,\"F\"),\n",
        "        (96,58,\"M\"), (97,54,\"F\"), (98,46,\"M\"), (99,35,\"F\"), (100,38,\"F\")\n",
        "    ]\n",
        "]\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(df.head())\n",
        "print(df.tail())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Una clínica está evaluando dos tratamientos para reducir síntomas de migraña.\n",
        "Después de 7 días de tratamiento, cada paciente clasifica la severidad de su migraña según esta escala ordinal estandarizada:\n",
        "\n",
        "1. Sin dolor\n",
        "2. Dolor leve\n",
        "3. Dolor moderado\n",
        "4. Dolor severo\n",
        "5. Dolor muy severo\n",
        "\n",
        "La escala es **categórica, pero con orden natural**.\n",
        "\n",
        "Se registran los datos de severidad para dos grupos:\n",
        "\n",
        "* Grupo A: Tratamiento clásico\n",
        "* Grupo B: Nuevo tratamiento experimental\n",
        "\n",
        "La clínica quiere determinar si **las distribuciones** de severidad son diferentes entre ambos grupos.\n",
        "\n",
        "## Datos obtenidos\n",
        "\n",
        "Grupo A (n = 60):\n",
        "\n",
        "| Severidad | Frecuencia |\n",
        "| --------- | ---------- |\n",
        "| 1         | 15         |\n",
        "| 2         | 22         |\n",
        "| 3         | 34         |\n",
        "| 4         | 24         |\n",
        "| 5         | 15         |\n",
        "\n",
        "Grupo B (n = 55):\n",
        "\n",
        "| Severidad | Frecuencia |\n",
        "| --------- | ---------- |\n",
        "| 1         | 20         |\n",
        "| 2         | 30         |\n",
        "| 3         | 25         |\n",
        "| 4         | 17         |\n",
        "| 5         | 13         |\n",
        "\n",
        "\n",
        "¿Las distribuciones de severidad de migraña después de 7 días son estadísticamente diferentes entre el tratamiento clásico (A) y el experimental (B), según el test de Kolmogorov–Smirnov?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmsT5tZ-v-W2"
      },
      "source": [
        "### Tests de igualdad de varianza"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "p4EGx27Nv-W2",
        "outputId": "35d912cf-5acb-47f3-d6ba-974550ed3151"
      },
      "outputs": [],
      "source": [
        "import sklearn.datasets as datasets\n",
        "\n",
        "iris = datasets.load_iris(as_frame=True)\n",
        "\n",
        "iris[\"frame\"].groupby(\"target\").var()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6XVGLrMv-W2"
      },
      "source": [
        "### F test de igualdad de varianzas\n",
        "\n",
        "* Evalúa si **dos poblaciones normales** tienen **la misma varianza**.\n",
        "* **Hipótesis nula (H₀):** las varianzas poblacionales son **iguales**.\n",
        "* **Hipótesis alternativa (H₁):** las varianzas son **diferentes** (o una es mayor que la otra, según el contraste).\n",
        "* El estadístico se define como el **cociente entre las dos varianzas muestrales**:\n",
        "\n",
        "  $ F = \\frac{s_1^2}{s_2^2} $\n",
        "\n",
        "  (conviene poner la mayor arriba para evitar valores menores que 1).\n",
        "* Se compara el valor observado con la **distribución teórica F**, con grados de libertad\n",
        "\n",
        "  $ (n_1 - 1, n_2 - 1) $\n",
        "\n",
        "* A partir de esa distribución se obtiene el **valor p**, que indica si la diferencia observada es compatible con H₀.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "ByyMQMaqv-W2",
        "outputId": "45eeb861-6725-49be-8202-3f928a85638e"
      },
      "outputs": [],
      "source": [
        "g1 = iris[\"frame\"].loc[iris[\"frame\"][\"target\"]==0, \"sepal length (cm)\"]\n",
        "g2 = iris[\"frame\"].loc[iris[\"frame\"][\"target\"]==1, \"sepal length (cm)\"]\n",
        "\n",
        "fig, axes = plt.subplots()\n",
        "for i, d in enumerate((g1, g2)):\n",
        "  x = np.linspace(-0.3, 0.3, len(d))\n",
        "  axes.scatter(x+i, d-d.mean(), label = f\"G{i+1}\")\n",
        "axes.set_ylim(-2, 2)\n",
        "axes.legend(loc=\"lower left\")\n",
        "axes.set_ylabel(\"data - mean(data)\")\n",
        "axes.set_xlabel(\"Grupos\")\n",
        "axes.set_xticks([])\n",
        "plt.legend()\n",
        "fig.tight_layout()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uH-K2DlRv-W2"
      },
      "source": [
        "Comprobemos que las distribuciones \"son\" normales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Y55luD7v-W2",
        "outputId": "3e6559c4-e2bb-4b0d-85b6-d8699da31432"
      },
      "outputs": [],
      "source": [
        "r1 = st.shapiro(g1)\n",
        "r2 = st.shapiro(g2)\n",
        "for x in (r1, r2):\n",
        "  print(x.pvalue)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gN9XuS8v-W3"
      },
      "source": [
        "Calculamos el estadístico F y el pvalue."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "8teuVECnv-W3",
        "outputId": "16ebed5f-0de3-47da-b430-358b44e2d87b"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "f_statistic = g2.var() / g1.var()\n",
        "pvalue = 1 - st.f.cdf(\n",
        "  f_statistic,\n",
        "  g1.size-1,\n",
        "  g2.size-1\n",
        ")\n",
        "\n",
        "pvalue2 = st.f.cdf(\n",
        "  f_statistic,\n",
        "  g1.size-1,\n",
        "  g2.size-1\n",
        ")\n",
        "\n",
        "x = np.linspace(0, 2.5, 100)\n",
        "xf = np.linspace(0, f_statistic, 100)\n",
        "\n",
        "plt.plot(x, st.f.pdf(x, g1.size-1, g2.size-1))\n",
        "plt.fill_between(xf, st.f.pdf(xf, g1.size-1, g2.size-1), color=\"lightblue\")\n",
        "plt.annotate(\n",
        "  xy = (1.6, 0.15),\n",
        "  xytext = (1.35, 0.75),\n",
        "  text = f\"$P_{{val}}$ = $1-CDF_F(f)$ = {pvalue:0.3f}\",\n",
        "  arrowprops = {\"arrowstyle\": \"->\"},\n",
        "  fontsize = 14\n",
        ")\n",
        "plt.scatter([f_statistic], [0], color = \"green\")\n",
        "plt.annotate(\n",
        "  xy = (f_statistic, 0),\n",
        "  xytext = (0.6, 0.35),\n",
        "  text = f\"F = $\\\\frac{{S_{{g1}}^2}}{{S_{{g2}}^2}}$ = {f_statistic:0.2f}\",\n",
        "  arrowprops = {\"arrowstyle\": \"->\"},\n",
        "  fontsize = 14\n",
        ")\n",
        "plt.tight_layout()\n",
        "\n",
        "print(f\"F es: {f_statistic}\")\n",
        "print(f\"El pvalue es: {pvalue}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q134lHXkv-W3"
      },
      "source": [
        "#### test de Bartlett de igualdad de varianzas\n",
        "\n",
        "El método (o test) de Bartlett es una prueba estadística para verificar si varias poblaciones tienen **varianzas iguales**.\n",
        "Se usa típicamente antes de aplicar ANOVA, donde uno de los supuestos clave es la igualdad de varianzas entre grupos.\n",
        "\n",
        "Sirve para contrastar:\n",
        "\n",
        "* Hipótesis nula: todas las varianzas poblacionales son iguales\n",
        "\n",
        "  $ H_0: \\sigma_1^2 = \\sigma_2^2 = \\dots = \\sigma_k^2 $\n",
        "\n",
        "* Hipótesis alternativa: al menos una varianza difiere\n",
        "\n",
        "  $ H_1: \\text{no todas las } \\sigma_i^2 \\text{ son iguales} $\n",
        "\n",
        "Supón que tienes:\n",
        "\n",
        "* $k$ grupos o muestras independientes, por ejemplo, 3 tratamientos distintos.\n",
        "* El grupo $i$ tiene tamaño $n_i$ y varianza muestral $s_i^2$.\n",
        "\n",
        "La idea de Bartlett es comparar las varianzas muestrales $s_i^2$ con una varianza \"combinada\" o \"pooled\" que asume que todas las varianzas son iguales bajo $H_0$.\n",
        "\n",
        "#### Supuestos del test de Bartlett\n",
        "\n",
        "1. **Normalidad** en cada grupo:\n",
        "   Los datos en cada grupo deben provenir de poblaciones aproximadamente normales.\n",
        "   El test de Bartlett es **muy sensible** a desviaciones de normalidad.\n",
        "\n",
        "   * Si los datos no son normales, el test puede indicar diferencias de varianzas donde en realidad solo hay asimetría o colas pesadas.\n",
        "\n",
        "2. **Independencia** de las observaciones:\n",
        "   Las muestras deben ser independientes entre sí y dentro de cada grupo.\n",
        "\n",
        "3. **Medición en escala al menos de intervalo**:\n",
        "   Deben tener sentido varianzas y promedios.\n",
        "\n",
        "#### Interpretación\n",
        "\n",
        "Supón que tienes 3 grupos:\n",
        "\n",
        "* Grupo 1: (n_1 = 10), (s_1^2 = 4.0)\n",
        "* Grupo 2: (n_2 = 12), (s_2^2 = 3.5)\n",
        "* Grupo 3: (n_3 = 9), (s_3^2 = 4.2)\n",
        "\n",
        "En general:\n",
        "\n",
        "* Si las varianzas son similares entre sí, el estadístico de Bartlett será pequeño y el p-value grande → no se rechaza $H_0$.\n",
        "* Si una de las varianzas es muy distinta (mucho mayor o mucho menor), el estadístico crece → p-value pequeño → se rechaza $H_0$.\n",
        "\n",
        "### Desventajas\n",
        "\n",
        "* Es **muy sensible a la falta de normalidad**. Incluso ligera no-normalidad puede distorsionar resultados.\n",
        "* En presencia de datos sesgados o con outliers, puede dar falsos positivos (rechazar homogeneidad cuando sí hay).\n",
        "\n",
        "Por estas razones, cuando la normalidad es cuestionable, se suele preferir:\n",
        "\n",
        "* Test de Levene\n",
        "* Test de Brown–Forsythe\n",
        "\n",
        "Estos son más **robustos** frente a desviaciones de normalidad, aunque algo menos potentes cuando la normalidad sí se cumple.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TAmATssv-W3",
        "outputId": "8f94e35a-00a1-4fca-9ca2-c7fa866f8681"
      },
      "outputs": [],
      "source": [
        "a = st.bartlett(g1, g2)\n",
        "b = 1 - st.chi2.cdf(a.statistic, 1)\n",
        "print(a, b)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZ1F8KB0v-W3",
        "outputId": "4b7de431-73f6-4c52-c71f-155057f21dd3"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "A = [85, 86, 88, 75, 78, 94, 98, 79, 71, 80]\n",
        "B = [91, 92, 93, 85, 87, 84, 82, 88, 95, 96]\n",
        "C = [79, 78, 88, 94, 92, 85, 83, 85, 82, 81]\n",
        "D = [59, 68, 99, 93, 72, 65, 73, 82, 72, 89]\n",
        "\n",
        "a = st.bartlett(A, B, C, D)\n",
        "b = 1 - st.chi2.cdf(a.statistic, 3)\n",
        "fig, axes = plt.subplots()\n",
        "for i, d in enumerate((A, B, C ,D)):\n",
        "    x = np.linspace(-0.3, 0.3, len(d))\n",
        "    axes.scatter(x+i, d, label = f\"G{i}\")\n",
        "axes.set_ylim(20, 110)\n",
        "axes.legend(loc=\"lower left\")\n",
        "axes.text(\n",
        "    x = 1.5,\n",
        "    y = 30,\n",
        "    s = (\n",
        "        f\"Bartlett Statistic ($B_S$) = {a.statistic:0.3f}\\n\"\n",
        "        f\"Bartlett P-Value = {a.pvalue:0.5f}\\n\"\n",
        "        f\"$1 - CDF_T(B_S)$ = {b:0.5f}\"\n",
        "    )\n",
        ")\n",
        "fig.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mc--RmXYv-W4"
      },
      "source": [
        "#### Test de igualdad de varianzas de Levene\n",
        "\n",
        "El **test de Levene** es una prueba estadística que evalúa si varios grupos independientes tienen **varianzas iguales** (homocedasticidad).\n",
        "Es una alternativa **más robusta** al test de Bartlett, especialmente cuando los datos no son normales o contienen outliers.\n",
        "\n",
        "El test contrasta:\n",
        "\n",
        "* Hipótesis nula:\n",
        "\n",
        "  $ H_0: \\sigma_1^2 = \\sigma_2^2 = \\dots = \\sigma_k^2 $\n",
        "\n",
        "* Hipótesis alternativa:\n",
        "\n",
        "  $ H_1: \\text{al menos una varianza difiere} $\n",
        "\n",
        "#### Por qué existe Levene\n",
        "\n",
        "El test de Bartlett funciona muy bien bajo normalidad, pero es **extremadamente sensible** a desviaciones de normalidad.\n",
        "Levene fue creado para resolver esto. Usa transformaciones basadas en distancias a la mediana o media para reducir la influencia de valores extremos y colas pesadas.\n",
        "\n",
        "Cómo funciona el test de Levene:\n",
        "\n",
        "- Se elige una medida de centro\n",
        "\n",
        "Hay tres versiones principales:\n",
        "\n",
        "1. **Clásico de Levene:** usa la **media**\n",
        "\n",
        "   $ Z_{ij} = |X_{ij} - \\bar{X}_i| $\n",
        "\n",
        "2. **Brown–Forsythe (versión robusta):** usa la **mediana**\n",
        "\n",
        "   $ Z_{ij} = |X_{ij} - \\tilde{X}_i| $\n",
        "\n",
        "   Esta es la versión más recomendada porque minimiza el efecto de outliers.\n",
        "\n",
        "\n",
        "- Crear las variables transformadas\n",
        "\n",
        "Para cada grupo (i) y cada observación (j), se calculan los valores absolutos:\n",
        "\n",
        "$ Z_{ij} = |X_{ij} - \\text{centro}_i| $\n",
        "\n",
        "donde “centro” es la media o mediana del grupo.\n",
        "\n",
        "- Aplicar ANOVA a los valores $Z_{ij}$\n",
        "\n",
        "El test de Levene es en realidad un ANOVA aplicado a los $Z_{ij}$.\n",
        "\n",
        "* Se calcula la media de cada grupo de (Z_{ij})\n",
        "* Se compara si esas medias son iguales entre grupos\n",
        "\n",
        "Es decir, se evalúa:\n",
        "\n",
        "$ H_0: \\text{las medias de } Z_{ij} \\text{ son iguales en todos los grupos} $\n",
        "\n",
        "Si las distancias promedio a la media/mediana son iguales entre grupos → las varianzas son iguales.\n",
        "\n",
        "#### Ventajas del test de Levene\n",
        "\n",
        "1. **Robusto a la no normalidad**\n",
        "   Funciona incluso cuando los datos son asimétricos o tienen colas largas.\n",
        "\n",
        "2. **Robusto a outliers**\n",
        "   Especialmente en su versión Brown–Forsythe.\n",
        "\n",
        "3. **Aplicable a muchos grupos**\n",
        "   Funciona igual para 2 o más grupos.\n",
        "\n",
        "#### Desventajas\n",
        "\n",
        "1. Menos potente que Bartlett cuando la normalidad sí se cumple perfectamente.\n",
        "2. Si los datos tienen distribuciones extremadamente raras o multimodales, la robustez disminuye (pero aún es mejor que Bartlett)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trFCSj5ov-W4",
        "outputId": "785b3059-cfd9-4b18-952a-583ec46ed6f2"
      },
      "outputs": [],
      "source": [
        "levene_result = st.levene(g1, g2)\n",
        "levene_stat = levene_result.statistic\n",
        "levene_pval = levene_result.pvalue\n",
        "print(1 - st.f.cdf(levene_stat, 1, 98))\n",
        "print(levene_pval)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ejercicios\n",
        "\n",
        "Toma los datos del dataset iris y comprueba si las varianzas de cada especie son estadísticamente\n",
        "diferentes o no, para cada una de las cuatro variables numéricas.\n",
        "\n",
        "Usa todos los métodos que vimos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kl7afuDEv-W4"
      },
      "source": [
        "### Test de igualdad de medias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCU5nqHIv-W4"
      },
      "source": [
        "### Test de Student para dos muestras\n",
        "\n",
        "- Asume que las varianzas son iguales\n",
        "  - existe una alternativa a este test:\n",
        "    - test de Welch\n",
        "    - no requiere asumir esta condición"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "E3R2xQeiv-W4",
        "outputId": "9ba68658-4ea7-4a80-cff7-b5ccb9794771"
      },
      "outputs": [],
      "source": [
        "sample_one = st.lognorm.rvs(\n",
        "    s=1,\n",
        "    size = 30\n",
        ")\n",
        "sample_two = st.norm.rvs(\n",
        "    scale = st.lognorm.std(s=1),\n",
        "    size = 30,\n",
        "    loc = st.lognorm.mean(s=1)\n",
        ")\n",
        "plt.hist(\n",
        "    [\n",
        "        sample_one,\n",
        "        sample_two\n",
        "    ],\n",
        "    bins = 10\n",
        ")\n",
        "plt.xlim(-3, 7)\n",
        "\n",
        "m1 = sample_one.mean()\n",
        "m2 = sample_two.mean()\n",
        "plt.plot([m1, m1],[0, 5], color = \"red\")\n",
        "plt.annotate(\n",
        "    xy = [m1, 5],\n",
        "    xytext = [0.95, 0.95],\n",
        "    ha = \"right\",\n",
        "    text = \"Mean LogNormal\",\n",
        "    textcoords = \"axes fraction\",\n",
        "    arrowprops = {\"arrowstyle\":\"->\"}\n",
        ")\n",
        "plt.plot([m2, m2],[0, 5], color = \"green\")\n",
        "plt.annotate(\n",
        "    xy = [m2, 5],\n",
        "    xytext = [0.95, 0.85],\n",
        "    textcoords = \"axes fraction\",\n",
        "    ha = \"right\",\n",
        "    text = \"Mean Normal\",\n",
        "    arrowprops = {\"arrowstyle\":\"->\"}\n",
        ")\n",
        "\n",
        "st.ttest_ind(sample_one, sample_two)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3rjxPFpv-W4"
      },
      "source": [
        "#### Test de Student para muestras apareadas\n",
        "\n",
        "- Las mediciones de ambas muestras\n",
        "  - corresponden a los mismos individuos\n",
        "  - en dos condiciones diferentes.\n",
        "  - Por ejemplo, antes y después de un tratamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIoBIOpHv-W5",
        "outputId": "048ee4b6-07af-4fba-a520-9b5378ddb6e8"
      },
      "outputs": [],
      "source": [
        "sample_one = st.uniform.rvs(size=20)\n",
        "effect = st.uniform.rvs(scale=0.01, size = 20)\n",
        "sample_two = sample_one + effect\n",
        "sample_three = st.uniform.rvs(size=20, loc=0.15)\n",
        "\n",
        "with_effect = st.ttest_rel(sample_one, sample_two)\n",
        "without_effect = st.ttest_rel(sample_one, sample_three)\n",
        "print(f\"El pvalue con efecto es {with_effect.pvalue}\")\n",
        "print(f\"El pvalue sin efecto es {without_effect.pvalue}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Alternativas no paramétricas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NMPkZOfv-W5"
      },
      "source": [
        "#### Mann Whitney U Test\n",
        "\n",
        "- Es un test no paramétrico.\n",
        "- Asume que:\n",
        "  - Las observaciones son independientes en ambos grupos.\n",
        "- La hipótesis nula asume que las distribuciones de las dos poblaciones son\n",
        "  iguales.\n",
        "- Es semejante a un test de medias:\n",
        "  - Dados x, y\n",
        "    - Tomados de las muestras X e Y\n",
        "  - La probabilidad de x > y es la misma que la de y > x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyCr6UhBv-W5",
        "outputId": "f51b0e57-dcad-4684-d775-9616e365c0ce"
      },
      "outputs": [],
      "source": [
        "sample_one = st.binom.rvs(n=10, p=0.3, size=20)\n",
        "sample_two = st.binom.rvs(n=10, p=0.45, size=80)\n",
        "\n",
        "st.mannwhitneyu(sample_one, sample_two)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkq1AN8Dv-W5"
      },
      "source": [
        "\n",
        "#### Wilcoxon signed rank text\n",
        "\n",
        "- Test para muestras pareadas\n",
        "- La hipótesis nula es que no hay un efecto:\n",
        "  - Se comprueba analizando el signo de las diferencias de ambas muestras.\n",
        "  - Se verifica si tiene una distribución binomial con p=0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "va1t1k4Mv-W5",
        "outputId": "74ed4ea0-ba50-44ec-c5ac-fc522d78c995"
      },
      "outputs": [],
      "source": [
        "sample_one = st.expon.rvs(size= 25)\n",
        "effect = st.uniform.rvs(size=25, scale=0.01)\n",
        "errors = st.norm.rvs(size=25, scale=0.01)\n",
        "sample_two = sample_one + effect + errors\n",
        "\n",
        "st.wilcoxon(sample_one, sample_two)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7O1h29nv-W6"
      },
      "source": [
        "Ejercicio: Calcular el pvalue usando la CDF de la distribución binomial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVwdlpuPv-W6"
      },
      "source": [
        "\n",
        "### Test de la mediana\n",
        "\n",
        "- Es un caso especial de la prueba de **chi-cuadrado**.\n",
        "- Se genera una tabla de contingencia:\n",
        "    - Se calcula la mediana para todos los datos ($x$ e $y$)\n",
        "    - Se arman grupos:\n",
        "      - por encima o por debajo de la mediana.\n",
        "      - las variables $x$ y $y$.\n",
        "- Esta prueba posee poco poder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmEKaQpqv-W6",
        "outputId": "4f3d444b-2d09-4f79-ed2d-214676e8ea4d"
      },
      "outputs": [],
      "source": [
        "sample_one = st.uniform.rvs(size = 25)\n",
        "sample_two = st.uniform.rvs(size = 45, loc=0.5)\n",
        "global_median = np.median(np.concatenate([sample_one, sample_two]))\n",
        "global_median\n",
        "data = [\n",
        "    [\n",
        "        (sample_one<=global_median).sum(),\n",
        "        (sample_one>global_median).sum()\n",
        "    ],\n",
        "    [\n",
        "        (sample_two<=global_median).sum(),\n",
        "        (sample_two>global_median).sum()\n",
        "    ],\n",
        "]\n",
        "data = np.array(data)\n",
        "data\n",
        "stat, pval, df, ex = st.contingency.chi2_contingency(data)\n",
        "print(f\"El p-value es {pval}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbujIV3Av-W7"
      },
      "source": [
        "### McNemar test\n",
        "\n",
        "- Se usa para buscar diferencias en tablas de contingencia (2x2)\n",
        "  - cuando se tienen muestra aparedas.\n",
        "- El uso típico es buscar cambios es individuos\n",
        "  - Antes vs. después de un tratamiento\n",
        "  - El tipo de variable que se mide es la misma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEiB8bFBv-W7",
        "outputId": "1a7e4897-570a-4367-a629-bd6d7f0c3bac"
      },
      "outputs": [],
      "source": [
        "from statsmodels.stats.contingency_tables import mcnemar\n",
        "\n",
        "data =[\n",
        "    ['stage_2', 'stage_1'], ['stage_1', 'stage_2'],\n",
        "    ['stage_2', 'stage_1'], ['stage_1', 'stage_1'],\n",
        "    ['stage_1', 'stage_1'], ['stage_2', 'stage_1'],\n",
        "    ['stage_2', 'stage_1'], ['stage_1', 'stage_1'],\n",
        "    ['stage_1', 'stage_1'], ['stage_1', 'stage_1'],\n",
        "    ['stage_1', 'stage_1'], ['stage_1', 'stage_2'],\n",
        "    ['stage_2', 'stage_1'], ['stage_2', 'stage_1'],\n",
        "    ['stage_1', 'stage_1'], ['stage_2', 'stage_1'],\n",
        "    ['stage_1', 'stage_1'], ['stage_2', 'stage_1'],\n",
        "    ['stage_1', 'stage_1'], ['stage_1', 'stage_1'],\n",
        "    ['stage_1', 'stage_1'], ['stage_2', 'stage_1'],\n",
        "    ['stage_1', 'stage_1'], ['stage_2', 'stage_2'],\n",
        "    ['stage_1', 'stage_1']\n",
        "]\n",
        "df = pd.DataFrame(\n",
        "    data,\n",
        "    columns = [\"before\", \"after_1y\"]\n",
        ")\n",
        "df\n",
        "\n",
        "elements, counts = st.contingency.crosstab(df[\"before\"], df[\"after_1y\"])\n",
        "\n",
        "df_counts = pd.DataFrame(counts)\n",
        "df_counts.index = [(\"before\", x) for x in elements[0]]\n",
        "df_counts.columns = [(\"after\", x) for x in elements[1]]\n",
        "print(df_counts)\n",
        "\n",
        "result = mcnemar(counts)\n",
        "\n",
        "result.pvalue\n",
        "\n",
        "# Y si las variables tienen más de dos valoresposibles.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Test de Mantel-Haenszel\n",
        "\n",
        "- Es una prueba estadística utilizada para evaluar si existe una asociación\n",
        "  entre dos variables categóricas,\n",
        "- Controlando o estratificando por una tercera variable categórica.\n",
        "- Es particularmente útil cuando se desea examinar la asociación entre dos\n",
        "  variables categóricas en presencia de un posible efecto de confusión de una\n",
        "  tercera variable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tenemos datos de:\n",
        "\n",
        "- un tratamiento de una droga contra un cierta enfermedad\n",
        "- en niños y en adultos\n",
        "- A la mitad de las personas se le administra la droga\n",
        "- a la otra mitad se le administra un placebo\n",
        "- El tratamiento dura seis meses\n",
        "  - luego se observa si hay una respuesta positiva o negativa en los síntomas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import scipy.stats as st\n",
        "! wget https://github.com/javieriserte/qualitative-data-course/raw/master/classes/cmh.data.csv\n",
        "df = pd.read_csv(\n",
        "  \"cmh.data.csv\",\n",
        "  header = [0],\n",
        "  sep = \",\"\n",
        ")\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Veamos con un test $\\chi^2$ si hay un efecto o no..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "table = pd.crosstab(df[\"tratamiento\"], df[\"respuesta\"])\n",
        "print(\"Tabla de contingencia:\\n\")\n",
        "print(table)\n",
        "stat, pvalue, dof, expected = st.contingency.chi2_contingency(table)\n",
        "print(\"\\np-value:\")\n",
        "print(pvalue)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Veamos como son las tablas de contingencia estratificando por edad."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "table = pd.crosstab(df[\"respuesta\"], [df[\"edad\"], df[\"tratamiento\"]])\n",
        "table"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "¿Hay algún efecto en cada estrato?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "statistic, pvalue, dof, expected = st.contingency.chi2_contingency(table[(\"adulto\", )])\n",
        "print(f\"p-value:{pvalue}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "statistic, pvalue, dof, expected = st.contingency.chi2_contingency(table[(\"menor\", )])\n",
        "print(f\"p-value:{pvalue}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test de Mantel-Haenszel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "cmh_result = sm.stats.StratifiedTable(\n",
        "  [\n",
        "    table[(\"menor\",)],\n",
        "    table[(\"adulto\", )]\n",
        "  ]\n",
        ").test_null_odds()\n",
        "print(cmh_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Ejercicios\n",
        "\n",
        "Usa los datos del ejercicio previo de \"Nocturnis Pharma\" y \"Oldergen Labs\" y\n",
        "haz un nuevo análisis, teniendo en cuenta que el sexo puede ser una variable de\n",
        "confusión\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "  \"Sujeto\": list(range(1, 51)),\n",
        "  \"Antes\": [\n",
        "    \"Negativo\",\"Positivo\",\"Negativo\",\"Positivo\",\"Positivo\",\n",
        "    \"Positivo\",\"Negativo\",\"Negativo\",\"Positivo\",\"Negativo\",\n",
        "    \"Positivo\",\"Positivo\",\"Positivo\",\"Positivo\",\"Positivo\",\n",
        "    \"Positivo\",\"Positivo\",\"Positivo\",\"Negativo\",\"Negativo\",\n",
        "    \"Positivo\",\"Positivo\",\"Positivo\",\"Positivo\",\"Positivo\",\n",
        "    \"Positivo\",\"Negativo\",\"Positivo\",\"Negativo\",\"Negativo\",\n",
        "    \"Positivo\",\"Negativo\",\"Positivo\",\"Negativo\",\"Positivo\",\n",
        "    \"Positivo\",\"Positivo\",\"Negativo\",\"Positivo\",\"Positivo\",\n",
        "    \"Positivo\",\"Negativo\",\"Negativo\",\"Negativo\",\"Positivo\",\n",
        "    \"Negativo\",\"Positivo\",\"Positivo\",\"Positivo\",\"Positivo\"\n",
        "  ],\n",
        "  \"A_las_12_hs\": [\n",
        "    \"Negativo\",\"Positivo\",\"Negativo\",\"Negativo\",\"Negativo\",\n",
        "    \"Negativo\",\"Negativo\",\"Negativo\",\"Positivo\",\"Negativo\",\n",
        "    \"Positivo\",\"Positivo\",\"Positivo\",\"Positivo\",\"Positivo\",\n",
        "    \"Positivo\",\"Positivo\",\"Positivo\",\"Negativo\",\"Negativo\",\n",
        "    \"Positivo\",\"Positivo\",\"Positivo\",\"Positivo\",\"Positivo\",\n",
        "    \"Positivo\",\"Positivo\",\"Positivo\",\"Negativo\",\"Negativo\",\n",
        "    \"Positivo\",\"Negativo\",\"Negativo\",\"Negativo\",\"Positivo\",\n",
        "    \"Positivo\",\"Positivo\",\"Positivo\",\"Positivo\",\"Positivo\",\n",
        "    \"Positivo\",\"Negativo\",\"Negativo\",\"Negativo\",\"Positivo\",\n",
        "    \"Negativo\",\"Positivo\",\"Positivo\",\"Positivo\",\"Positivo\"\n",
        "  ],\n",
        "  \"A_las_24_hs\": [\n",
        "    \"Negativo\",\"Positivo\",\"Negativo\",\"Negativo\",\"Negativo\",\n",
        "    \"Negativo\",\"Negativo\",\"Negativo\",\"Positivo\",\"Negativo\",\n",
        "    \"Positivo\",\"Positivo\",\"Positivo\",\"Negativo\",\"Positivo\",\n",
        "    \"Positivo\",\"Negativo\",\"Positivo\",\"Negativo\",\"Negativo\",\n",
        "    \"Positivo\",\"Positivo\",\"Positivo\",\"Positivo\",\"Positivo\",\n",
        "    \"Negativo\",\"Negativo\",\"Positivo\",\"Negativo\",\"Negativo\",\n",
        "    \"Positivo\",\"Negativo\",\"Negativo\",\"Negativo\",\"Positivo\",\n",
        "    \"Positivo\",\"Positivo\",\"Positivo\",\"Positivo\",\"Positivo\",\n",
        "    \"Positivo\",\"Negativo\",\"Positivo\",\"Negativo\",\"Positivo\",\n",
        "    \"Negativo\",\"Negativo\",\"Negativo\",\"Positivo\",\"Positivo\"\n",
        "  ]\n",
        "}\n",
        "\n",
        "# Se tienen datos del tratamiento de un grupo de personas, a las mismas personas\n",
        "# se los evalua a las 12 horas y a las 24 horas. Comprobar si hay un efecto del\n",
        "# tratamiento.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
