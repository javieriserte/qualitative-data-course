---
title: "Examen_ AGUER, CANTORE,  GIOMI, MANEIRO "
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(MASS)
library(klaR)
library(mda)
library(ggplot2)
library(ROCR)
```

## Condideraciones generales

El trabajo final consiste de cuatro ejercicios. Se puede resolver de forma
individual o en grupos de hasta tres personas.

La entrega debe ser un único archivo de R o R markdown e incluir el código
ejecutable y comentarios con la explicación y justificación de cada punto
pedido.

La fecha final de entrega es el último día hábil del mes de Junio de 2020.

## Ejercicio 1 - Confírmeros de RMN 

La técnica de resonancia magnética nuclear (RMN) permite la obtención de estructuras
de proteínas en solución. A diferencia de la difracción de rayos X, es posible 
obtener estructuras de múltiples confírmeros mediante RMN en un solo expertimento.

La similitud entre dos estructuras de la misma proteina se puede medir calculando
el RMSD (Root Mean Square Deviation) entre sus átomos luego de alinear ambas 
estructuras. Se pude considerar que es RMSD como una medida de distancia, cuanto
menor sea este valor, más similares son las estructuras y si es cero implica que
las estructuras son idénticas.

En los datos proporcianados debajo, se tiene una matriz de distancia obtenida
para veinte confórmeros de la proteína 16-1 del floema de Arabidopsis thaliana.

- Realice un clustering jerárquico de los confirmeros a partir de los datos.
- Genere una visualización del árbol jerárquico, elija un número de clusters de 
  acuerdo a su interpretación del gráfico y corte el árbol para obtener los grupos.
- Genere una visualización usando la técnica de escalas multidimensionales (MDS).
  Asigne un color a cada punto un color de acuerdo a los grupos obtenidos.
- Repita el corte del árbol usando dynamicTreeCut, repita la visualicación por
  MDS.

```{r}
# Este código genera los datos necessarios para el ejercicio
# Ejecute el código obtener la matriz de distancias.
dist_data <- data.frame(
  model_01 = c(0, 16.4852, 26.7001, 6.6758, 25.6860, 17.2724, 16.4360, 17.5262, 5.7859, 4.5729, 7.3545, 16.2985, 27.9932, 15.6142, 20.5686, 9.3243, 17.8689, 23.9115, 10.3299, 17.2828),
  model_02 = c(16.4852, 0, 18.2345, 17.7663, 16.3651, 11.7960, 8.2189, 10.8417, 15.2919, 16.4171, 16.9726, 13.7641, 18.3786, 14.3336, 11.6759, 17.1467, 11.2420, 16.8094, 13.8109, 9.7168),
  model_03 = c(26.7001, 18.2345, 0, 24.9232, 10.1868, 21.4135, 14.6915, 14.5236, 23.4392, 26.3174, 24.9146, 14.3248, 11.5938, 17.7416, 14.0819, 23.1910, 11.6983, 5.7072, 22.7548, 12.6613),
  model_04 = c(6.6758, 17.7663, 24.9232, 0, 24.0685, 16.6095, 16.4687, 17.1476, 5.2863, 5.8117, 4.9092, 14.5118, 26.3781, 13.4018, 21.3679, 5.9685, 17.0221, 22.1496, 8.6671, 16.8856),
  model_05 = c(25.6860, 16.3651, 10.1868, 24.0685, 0, 16.1106, 15.2739, 16.7502, 22.4373, 25.0151, 23.1993, 13.3762, 6.1724, 13.9120, 17.6865, 21.5592, 13.8006, 10.6359, 20.0988, 13.9501),
  model_06 = c(17.2724, 11.7960, 21.4135, 16.6095, 16.1106, 0, 14.4798, 17.2628, 15.2802, 15.9306, 14.9138, 15.1275, 17.7061, 10.7905, 20.2664, 14.7562, 17.0877, 20.1955, 10.3066, 15.7021),
  model_07 = c(16.4360, 8.2189, 14.6915, 16.4687, 15.2739, 14.4798, 0, 6.1707, 14.5125, 16.2804, 16.4638, 10.9738, 17.2864, 13.7019, 9.7053, 15.8147, 7.5667, 12.4539, 14.3201, 5.1190),
  model_08 = c(17.5262, 10.8417, 14.5236, 17.1476, 16.7502, 17.2628, 6.1707, 0, 15.4003, 17.7589, 17.6089, 10.9059, 18.4387, 14.6958, 9.3566, 16.5306, 6.8907, 11.9384, 16.3907, 5.7788),
  model_09 = c(5.7859, 15.2919, 23.4392, 5.2863, 22.4373, 15.2802, 14.5125, 15.4003, 0, 5.8535, 5.4776, 12.8612, 24.8279, 12.1619, 18.9797, 6.3361, 15.0996, 20.5545, 7.8011, 14.8662),
  model_10 = c(4.5729, 16.4171, 26.3174, 5.8117, 25.0151, 15.9306, 16.2804, 17.7589, 5.8535, 0, 5.9455, 16.1058, 27.3436, 14.7760, 21.2119, 8.1079, 17.9523, 23.6218, 8.6544, 17.3343),
  model_11 = c(7.3545, 16.9726, 24.9146, 4.9092, 23.1993, 14.9138, 16.4638, 17.6089, 5.4776, 5.9455, 0, 14.0077, 25.4121, 12.1996, 21.7709, 5.3425, 17.2134, 22.1693, 7.0570, 16.9675),
  model_12 = c(16.2985, 13.7641, 14.3248, 14.5118, 13.3762, 15.1275, 10.9738, 10.9059, 12.8612, 16.1058, 14.0077, 0, 15.3454, 7.7219, 15.2254, 11.7657, 8.6621, 11.5023, 13.0254, 9.2705),
  model_13 = c(27.9932, 18.3786, 11.5938, 26.3781, 6.1724, 17.7061, 17.2864, 18.4387, 24.8279, 27.3436, 25.4121, 15.3454, 0, 15.6845, 19.9546, 23.6483, 15.9775, 12.4275, 22.0478, 16.2506),
  model_14 = c(15.6142, 14.3336, 17.7416, 13.4018, 13.9120, 10.7905, 13.7019, 14.6958, 12.1619, 14.7760, 12.1996, 7.7219, 15.6845, 0, 19.1618, 9.8197, 12.9266, 15.5429, 10.1634, 13.0122),
  model_15 = c(20.5686, 11.6759, 14.0819, 21.3679, 17.6865, 20.2664, 9.7053, 9.3566, 18.9797, 21.2119, 21.7709, 15.2254, 19.9546, 19.1618, 0, 21.3889, 9.5500, 13.0831, 20.3184, 9.0762),
  model_16 = c(9.3243, 17.1467, 23.1910, 5.9685, 21.5592, 14.7562, 15.8147, 16.5306, 6.3361, 8.1079, 5.3425, 11.7657, 23.6483, 9.8197, 21.3889, 0, 15.8248, 20.3619, 7.5788, 15.8322),
  model_17 = c(17.8689, 11.2420, 11.6983, 17.0221, 13.8006, 17.0877, 7.5667, 6.8907, 15.0996, 17.9523, 17.2134, 8.6621, 15.9775, 12.9266, 9.5500, 15.8248, 0, 9.0847, 15.9460, 5.4431),
  model_18 = c(23.9115, 16.8094, 5.7072, 22.1496, 10.6359, 20.1955, 12.4539, 11.9384, 20.5545, 23.6218, 22.1693, 11.5023, 12.4275, 15.5429, 13.0831, 20.3619, 9.0847, 0, 20.4288, 10.1646),
  model_19 = c(10.3299, 13.8109, 22.7548, 8.6671, 20.0988, 10.3066, 14.3201, 16.3907, 7.8011, 8.6544, 7.0570, 13.0254, 22.0478, 10.1634, 20.3184, 7.5788, 15.9460, 20.4288, 0, 15.2810),
  model_20 = c(17.2828, 9.7168, 12.6613, 16.8856, 13.9501, 15.7021, 5.1190, 5.7788, 14.8662, 17.3343, 16.9675, 9.2705, 16.2506, 13.0122, 9.0762, 15.8322, 5.4431, 10.1646, 15.2810, 0)
)
rownames(dist_data) <- colnames(dist_data)
dist_data <- as.dist(dist_data)

```

- Realice un clustering jerárquico de los confirmeros a partir de los datos.

**Generación del cluster jerárquico con la función hclust y los datos de la matriz de distancia**.

```{r}
cluster <- hclust(dist_data)
```


-Genere una visualización del árbol jerárquico, elija un número de clusters de 
  acuerdo a su interpretación del gráfico y corte el árbol para obtener los grupos.
  
```{r}
plot(cluster)
set.seed(123)
members <- cutree(cluster,k=4) # k= número de grupos
members
```

**utilizamos la función cutree para formar los cluster. De acuerdo a la visuliacion del plot, decidimos fijar el parámetro k=4 (número de grupos)**


- Genere una visualización usando la técnica de escalas multidimensionales (MDS).
  Asigne un color a cada punto un color de acuerdo a los grupos obtenidos.

```{r}
fit <- cmdscale(dist_data,eig=TRUE, k=2) # k es el numero de dimensiones
#fit

# plot
x <- fit$points[,1]
y <- fit$points[,2]
plot(x, y, xlab="Coordinate 1", ylab="Coordinate 2", type="n")
text(x, y, labels = members, cex = 0.8,  col=members)
```

**Utilizamos la función cmdscale para trasnformar la matriz de distancia en un SET de 2 coordenadas(K=2)**
**Graficamos los valores (points) obtenidos en la transformación de la matriz y coloreamos los grupos con la información del paso anterior (members)**
> Podrían usar las etiquetas de cada modelo en lugar de números en el gráfico
> para que la comparación con el árbol sea más directa.

- Repita el corte del árbol usando dynamicTreeCut, repita la visualización por
  MDS.

```{r}
library(dynamicTreeCut)
DIN_T <- cutreeDynamic(cluster, distM = as.matrix(dist_data), minClusterSize = 2, cutHeight = 25)
DIN_T

# plot
x <- fit$points[,1]
y <- fit$points[,2]
plot(x, y, xlab="Coordinate 1", ylab="Coordinate 2", type="n")
text(x, y, labels = DIN_T, cex = 0.8,  col=DIN_T)

?cutreeDynamic
```

**La función cutreeDynamic del paquete dynamicTreeCut, obtuvo 6 grupos en vez de los 4 determinados anteriormente.**
**Tuvimos que utilizar el argumento cutHeight = 25 para limitar la altura y  minClusterSize = 2, sino no obteniamos resultados**

> COMENTARIO: No es necesario modificar el argumento cutHeight, con el valor por
> defecto se obtiene el mismo resultado.




## Ejercicio 2 - Resultado de docking

El docking molecular es una técnica computacional que intenta predecir el sitio
de unión de una proteína con un ligando, otra prote?na, o un ?cido nucleico.

Los m?todos de docking suelen generar entre cientos a miles de posibles
estructuras de interacci?n entre las mol?culas. Una ?tapa com?n suele ser la de
generar grupos y luego analizar las propiedades de los grupos obtenidos.

En el archivo 'hdock_5ecae82ecf8f7.txt' se tienen datos del resultado de docking
para el pétido adrenomedullin 2 (ADM2) con el receptor CLR (calcitonin 
receptor-like) y la proteína RAMP1 (Receptor Activity-Modifying Protein 1).
El archivo contiene datos de más de 4000 estructuras del ligando. Las tres
primeras columnas corresponden a las coordenadas X, Y y Z del centro de rotación
del ligando, las siguientes tres rotaciones son las rotaciones en cada eje, 
la séptima es una medida de la energía del docking (cuanto menor es, la 
estructura es más estable. Los datos están ordenados por energía). Las últimas
columnas son datos internos del docking y no son relevantes para este ejercicio.

- Reliace un análisis de componentes principales con los datos de las primeras
  columnas (que describen la geometría).
- ¿que proporción de la varianza está representada en las dos primeras
  componentes?
- Proponga un número de clusters según su interpretación del gráfico y genere 
  esa cantidad de clusters usando kmeans.
- Rehaga el gráfico de PCA, asignando un color a cada punto de acuerdo a los
  grupos obtenidos.
- Haga un boxplot de la energíaa para cada grupo.
- Haga uno o más tests para decidir si la energ?a entre grupos es similar o no.

```{r}
# Cambiar la ruta de acceso al archivo.

docking_data <- read.table(choose.files())
colnames(docking_data) <- c("X", "Y", "Z", "Rot1", "Rot2", "Rot3", "Energ", "?", "?")
head(docking_data)
```

- Reliace un análisis de componentes principales con los datos de las primeras
  columnas (que describen la geometría).

**se realizó el PCA utilizando las variables 4,5 y 6 del archivo de datos (variables rotadas)**
> ¿Por qué no usaron las tres primeras columnas con las coordenadas en el espacio?

```{r}
pca <- prcomp(
  as.matrix(docking_data[4:6]),
  center=TRUE,
  scale=TRUE)

#names(pca)
summary(pca)

plot(
  pca$x[,"PC1"],
  pca$x[,"PC2"],
  pch=22
)
```

- ¿que proporción de la varianza está representada en las dos primeras
  componentes?
  
**Varianza explicada por PC1 y PC2= 81.88%.**

Importance of components:
                          PC1    PC2    PC3
Standard deviation     1.3037 0.8699 0.7373
Proportion of Variance 0.5665 0.2522 0.1812
Cumulative Proportion  0.5665 0.8188 1.0000



- Proponga un número de clusters según su interpretación del gráfico y genere 
  esa cantidad de clusters usando kmeans.
  
-Rehaga el gráfico de PCA, asignando un color a cada punto de acuerdo a los
  grupos obtenidos.
  
**El gráfico sugiere la presencia de 3 Clusters**


###Clusters (3) usando usando kmeans y gráfico usando colores por grupo.

```{r}
set.seed(123)
groups <- kmeans(
  x=docking_data[,4:6],
  centers=3
)


plot(
  pca$x[,"PC1"],
  pca$x[,"PC2"],
  pch=22,
  col=groups$cluster,
  bg=groups$cluster
)
```

- Haga un boxplot de la energía para cada grupo.

###BLOX PLOT para cada grupo (cluster)

```{r}
docking_data$cluster <- groups$cluster#columna agregada para identificar clusters.

library("RColorBrewer")
boxplot(Energ~cluster, data=docking_data, col=brewer.pal(n = 4, name = "RdBu"))

```

-Haga uno o más tests para decidir si la energía entre grupos es similar o no.

###ANOVA, Bonferroni y Tukey.

```{r}
anova_model<- aov(formula=Energ~as.factor(cluster),
  data=docking_data)

summary(anova_model)

#Bonferroni
pairwise.t.test(
  x=docking_data$Energ,
  g=docking_data$cluster,
  p.adjust.method = "bonferroni"
)

#Tukey
TukeyHSD(anova_model)

```
###ANOVA:

**El ANOVA indica que alguna de las medias de los grupos difiere en forma significativa**

###Bonferroni y Tukey

**Las medias entre grupos (clusters) para la variable Energia difieren significativamente para los grupos 1 vs 2 y 2 vs 3.**
**No hay diferencias significativas entre las medias para los grupos 1 vs 3**

> COMENTARIO: El cluster 2 parace ser diferente al los otros dos. Se podría 
> mostrar en sobre el gráfico, cual es ese cluster.


## Ejercicio 3 - Expresion de genes

Se quiere analizar una pequñaa red de regulación génica en un microorganismo
recientemente descubierto: Bacillus novusvillam.
Esta red está formada por ocho proteínas reguladores y treinta genes blancos de
regulación.

Analizando la secuencia promotora de cada gen blanco se encontraron putativas
regiones de unión de una o más de las proteínas regulatorias.

Se quiere construir un modelo lineal que pueda explicar la expresión de estos
genes, durante la fase de síntesis del ciclo celular, de acuerdo a la presencia
de las secuencias de unión a las proteínas regulatorias.

En la tabla de datos proporcionada, se tienen datos de la medición de la
expresión génica (durante la fase de síntesis) de cada uno de los genes blanco
en la primer columna, en las ocho siguientes columnas están codificada la
presencia (1) o ausencia (0) de cada la secuencia de unión de cada proteína
reguladora en el promotor del gen blanco. Finalmente, en la última columna, hay
una asignación de la función del gen blanco, en tres categorías: señalización,
metabolismo o respuesta a stress.

- Genere un modelo lineal simple para modelar la expresión de este conjunto de
  genes blanco.
- Haga una análisis discriminante lineal (LDA) para predecir la pertencia de 
  cada gen blanco a las categoríaas funcionales ("signaling", "Mmetabolism" y 
  "Stress"). Para ello, construya un conjunto de entrenamiento y otro de prueba.

```{r}
# Este código genera los datos necessarios para el ejercicio
# Ejecute el c?digo para obtener los datos de partida.
expdata <- data.frame(
  matrix(
    data=c(
      "11.076", "0", "1", "0", "1", "1", "0", "0", "1", "Signaling",
       "6.982", "0", "0", "1", "0", "0", "0", "1", "1", "Metabolism",
       "3.641", "0", "0", "1", "0", "1", "0", "0", "1", "Stress",
       "9.778", "0", "0", "1", "1", "1", "1", "0", "0", "Stress",
      "10.995", "0", "1", "0", "1", "0", "0", "1", "1", "Signaling",
       "7.213", "0", "1", "0", "1", "0", "1", "0", "1", "Signaling",
       "9.292", "0", "0", "1", "0", "1", "1", "1", "0", "Stress",
       "7.437", "0", "0", "0", "0", "1", "0", "1", "0", "Signaling",
       "1.381", "1", "0", "0", "0", "1", "1", "0", "1", "Signaling",
      "14.812", "0", "0", "1", "1", "0", "1", "1", "0", "Stress",
       "3.536", "1", "0", "0", "0", "1", "0", "0", "1", "Signaling",
       "8.384", "0", "0", "0", "0", "1", "0", "1", "1", "Metabolism",
       "5.433", "0", "0", "0", "0", "1", "1", "1", "1", "Signaling",
       "7.068", "1", "0", "0", "1", "1", "1", "0", "0", "Signaling",
      "-0.962", "1", "1", "0", "0", "1", "0", "0", "0", "Metabolism",
       "3.725", "0", "0", "1", "0", "1", "1", "0", "0", "Stress",
      "12.031", "1", "0", "0", "1", "0", "1", "1", "0", "Signaling",
       "2.779", "1", "0", "1", "0", "1", "0", "0", "1", "Metabolism",
       "4.730", "1", "1", "1", "0", "0", "0", "0", "1", "Metabolism",
      "13.597", "1", "1", "0", "1", "0", "0", "1", "0", "Metabolism",
       "8.690", "0", "1", "0", "1", "0", "0", "0", "1", "Metabolism",
       "2.394", "0", "1", "0", "0", "1", "1", "1", "0", "Signaling",
      "12.631", "0", "0", "0", "1", "0", "1", "1", "0", "Signaling",
       "9.043", "0", "0", "1", "0", "1", "0", "1", "0", "Stress",
      "11.414", "0", "0", "0", "1", "0", "0", "1", "1", "Signaling",
       "5.610", "0", "1", "1", "0", "0", "0", "1", "1", "Metabolism",
      "10.922", "0", "0", "1", "1", "1", "0", "0", "0", "Stress",
       "5.502", "1", "0", "0", "0", "1", "0", "0", "0", "Signaling",
       "3.769", "1", "1", "0", "0", "1", "0", "1", "0", "Metabolism",
       "2.601", "1", "1", "1", "0", "0", "1", "0", "0", "Metabolism"
      ),
    byrow = TRUE,
    ncol=10,
  ),
  stringsAsFactors = FALSE
)

expdata[,1] <- as.numeric(expdata[,1])
expdata[,2] <- as.numeric(expdata[,2])
expdata[,3] <- as.numeric(expdata[,3])
expdata[,4] <- as.numeric(expdata[,4])
expdata[,5] <- as.numeric(expdata[,5])
expdata[,6] <- as.numeric(expdata[,6])
expdata[,7] <- as.numeric(expdata[,7])
expdata[,8] <- as.numeric(expdata[,8])
expdata[,9] <- as.numeric(expdata[,9])
expdata[,10] <- factor(expdata[,10])
rownames(expdata) <- c(
  "BN43692", "BN14803", "BN09935", "BN41071", "BN79318", "BN28948", "BN57814",
  "BN29770", "BN05403", "BN99720", "BN59592", "BN83110", "BN08049", "BN97505",
  "BN04609", "BN44066", "BN50732", "BN68717", "BN16980", "BN60240", "BN66629",
  "BN55826", "BN48684", "BN82698", "BN09817", "BN53059", "BN92537", "BN09699",
  "BN36675", "BN33697"
)
colnames(expdata) <- c("Expr", "BN55201", "BN91693", "BN56179", "BN19314",
                       "BN41333", "BN41266", "BN56652", "BN02864", "Type")
head(expdata)
```

###Ejercicio 3_1
- Genere un modelo lineal simple para modelar la expresión de este conjunto de
  genes blanco.
  
  
###Modelo LINEAL de Expresión génecica (Exp) en funcion de secuencia de unión de cada proteína reguladora en el promotor del gen blanco (se excluye la variable 10).

```{r}
#modelo lineal

DATOS_LM <- expdata[,-10]# exclusión de la variable categórica.
#View(DATOS_LM)

model <-lm(Expr ~ ., data=DATOS_LM)
model
names(model)

coefficients(model)
residuals(model)
names(summary(model))
summary(model)$adj.r.squared
summary(model)

##PLOT predicciones vs Valores originales

plot(
  x=expdata$Expr,
  y=model$fitted.values,
  abline(lm(model$fitted.values ~expdata$Expr )),
  main="Predicción (Expr) vs Valores originales (Expr)",
  xlab="Valores originales (Expr)",
  ylab="Predicci?n (Expr)",
  col="red",
  pch=19
  )
r2 = summary(model)$adj.r.squared
mylabel = bquote(italic(R)^2 == .(format(r2, digits = 3)))
text(x = 19, y = 2.5, labels = mylabel)
legend("topleft", bty="n", legend=mylabel)
```

**El modelo explica el 83,6 % de la variacion de la Expresión génica**


###Control de los Supuestos del modelo de regresión lineal

```{r}
##Distribuci?n normal de los residuos:
qqnorm(model$residuals) 
qqline(model$residuals)
shapiro.test(model$residuals)

##Variabilidad constante de los residuos (homocedasticidad):

library(ggplot2)
ggplot(data = DATOS_LM, aes(model$fitted.values, model$residuals)) +
geom_point() +
geom_hline(yintercept = 0) +
theme_bw()
```

###Distribución normal de los residuos:

***Los residuos siguen una distribución Normal (p-valor Shapiro-test: 0.7058).***

###Variabilidad constante de los residuos (homocedasticidad):

**Los residuos frente a los valores ajustados por el modelo se distribuyen en forma aleatoria en torno a cero.**
***No hay evidencias de falta de homocedasticidad.***

- Haga una análisis discriminante lineal (LDA) para predecir la pertencia de 
  cada gen blanco a las categorias funcionales ("signaling", "Mmetabolism" y 
  "Stress"). Para ello, construya un conjunto de entrenamiento y otro de prueba.

```{r}
## definición de los grupos de entrenamineto (70%) y prueba (30%).
set.seed(123)
training_fraction = 0.7
training_index <- sample(
  1:nrow(expdata),
  training_fraction * nrow(expdata)
  )

training_set <- expdata[training_index, ]
testing_set <- expdata[-training_index, ]

##LDA

lda_model <- lda(
  Type ~ .,
  data=training_set
)

predictions <- predict(lda_model, testing_set)
predictions$class

###
print(
  paste(
    "Predicciones correctas:",
    sum(predictions$class==testing_set$Type),
    "de",
    length(predictions$class)
    )
)

mean(predictions$class==testing_set$Type)


plot(
  predictions$x[,1],
  predictions$x[,2],
  col=predictions$class,
  bg=testing_set$Type,
  pch=22,
  lwd=3,
  xlab="LD1",
  ylab="LD2"
)

```

***El Modelo ajustado por LDA tiene un acurracy de aprox. 78% (Predicciones correctas: 7 de 9") ***

## Ejercicio 4 - Covariación

El an?lisis de covariación de pares de residuos en un conjuntos de secuencias 
hom?logas de una prote?na permite predecir con cierta exactitud los contactos
tridimensionales en la estructura tridimensional de una prote?na.

El archivo "covdata.txt" contiene datos de los resultados de covariaci?n 
obtenidas por dos metodologías: Direct Coupling Analysis (DCA) y Mutual
Information (MI) para la prote?na tioredoxina. Cada fila de la tabla contiene
datos para un par de residuos de la prote?na. En los dos primeras columnas,
están los números de las posiciones de los residuos, en las dos columnas 
siguientes est?n los puntajes de covariaciones para los dos m?todos usados y
en la ?ltima columna dice si ese par de residuos est?n realmente en contacto en 
la estructura tridimensional de la prote?na (este valor no es una predicci?n, 
es 1 para los que est?n en contacto y 0 para los que no).

Se quiere obtener un método que combine información de los métodos usados para
mejorar la predicción. Como primer acercamiento, se quiere hacer una prueba con
una sola proteína.

- Genere una visualización de las curva ROC para la predicción de contactos para
  ambos métodos. Calcule el área bajo la curca (AUC) en cada caso.
- Haga una regresión logística para obtener un método que combine información
  de los otros dos métodos. Intente prededir los datos de contacto, a partir de
  ellos.
- Genere una nueva curva ROC y calcule el AUC para el nuevo método.

```{r}
# Cambie la ruta del archivo
cov_data <- read.table(choose.files())
head(cov_data)

```

### Método DCA

```{r}
DCA<- glm(
  is_contact ~ dca,
  data=cov_data,
  family = binomial(link = logit)
)
coefficients(DCA)

names(DCA)

dca_pred <- DCA$fitted.values
#View(dca_pred)


pred1 <- prediction(
  predictions = dca_pred,
  labels = cov_data$is_contact
)

perf1 <- performance(pred1,"tpr","fpr")
plot(perf1,colorize=TRUE)

auc_value_dca<- performance(pred1, "auc")@y.values[[1]]
auc_value_dca

```

###Método MI

```{r}
MI<- glm(
  is_contact ~ mi,
  data=cov_data,
  family = binomial(link = logit)
)
coefficients(MI)


mi_pred <- MI$fitted.values


pred2 <- prediction(
  predictions = mi_pred,
  labels = cov_data$is_contact
)

perf2 <- performance(pred2,"tpr","fpr")
plot(perf2,colorize=TRUE)

auc_value_mi <- performance(pred2, "auc")@y.values[[1]]
auc_value_mi
```

###Combinación Métodos DCA + MI

```{r}
DCA_MI<- glm(
  is_contact ~ mi + dca,
  data=cov_data,
  family = binomial(link = logit)
)
coefficients(DCA_MI)


DCA_MI_pred <- DCA_MI$fitted.values


pred3 <- prediction(
  predictions = DCA_MI_pred,
  labels = cov_data$is_contact
)

perf3 <- performance(pred3,"tpr","fpr")
plot(perf3,colorize=TRUE)

auc_value_DCA_MI <- performance(pred3, "auc")@y.values[[1]]
auc_value_DCA_MI
```

###LAS 3 CURVAS ROC


```{r}
AUC_DCA= paste("DCA_AUC=", format(auc_value_dca, digits = 2))
AUC_MI= paste("MI_AUC=", format(auc_value_mi, digits = 2))
AUC_DCA_MI= paste("DCA_MI_AUC=", format(auc_value_DCA_MI, digits = 2))


plot(perf1, col = "red", lty = 2, main = "ROC", lwd=2)
plot(perf2, col = "blue", lty = 3, add = TRUE, lwd=2)
plot(perf3, col = "green", lty = 2, add= TRUE, lwd=2)
abline(0, 1, col = "grey",lwd=2)
legend(x=0.5,y=0.2,c(AUC_DCA, AUC_MI, AUC_DCA_MI),cex=0.8, col=c("red", "blue", "green"),pch=c("-"), lwd=0.4)
```

**El nuevo método, combinando DCA y MI, precide mejor que los métodos por separado. AUC DCA + MI=0.91 > AUC DCA=0.84 > AUC MI=0.83.**

>  Muy buen trabajo. Sería conveniente que expliquen un poco más que están haciendo en cada paso.
